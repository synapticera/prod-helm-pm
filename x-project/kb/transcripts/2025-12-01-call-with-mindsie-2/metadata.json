{
  "date": "2025-12-02",
  "title": "call with mindsie 1",
  "description": "Bill Karpovich  0:01  \nHey, Soren, how you doing? Good,\n\nSoren Frederiksen  0:05  \ngood. We're still in the synaptic virtual office.\n\nBill Karpovich  0:11  \nI'm in a different, different one right now. Yeah, back, I guess. Yeah, we spoke on Friday, right? So, yeah, it was back back up in Maryland, where live normally was down at the North Carolina for the holiday, Thanksgiving. Yeah, thank you. Yeah. I appreciate it. Yeah. And Soren, as I mentioned, I that my colleague here Dan who wanted to join in and get acquainted and get a chance to talk a little bit following up on our conversation. So meet, meet Dan.\n\nSpeaker 1  0:47  \nDan, how you doing? I'm doing well. Soren, thanks for the time. Really appreciate it. Bill told me a little bit looking forward to learning about what you guys are up to and can offer.\n\nSoren Frederiksen  0:58  \nOh, is that a big computer in the background. Dan, or like, Oh,\n\nSpeaker 1  1:05  \nit is a like three in one, like CNC printer, laser engraver, and it is up and running because we're knocking out some personalized Christmas ornaments.\n\nSoren Frederiksen  1:24  \nOkay, so we do have a somewhat fellow nerd on the call here. It sounds\n\nBill Karpovich  1:29  \nlike, yeah, Dan's CTO, CPO. So okay, yeah.\n\nSoren Frederiksen  1:35  \nSo I used to be called the head nerd of mindzie. Took it off when we started talking to some bigger companies, but, yeah, it's, it's kind of how I see myself. But so I couple of things, I guess, with this, because it's, I normally don't do these, like you said, do like a customer presentation, right? I don't do those, right? I do the very technical presentation. So, so we'll carry it over a little bit, and I did a bit of an agenda, but, and I don't want to just go and sit here and go through PowerPoints, right? So it would much rather you just interrupt and ask questions. So I was thinking and like, maybe I can just show the agenda I kind of set up what I thought might be interesting for you, and then maybe, maybe maybe also just say if there's something else you want out of this, right? So, because I know, as far as I understood, you're trying to do it for, like, create, kind of your own platform, maybe OEM hours, or do something where you can use process mining, right? So yeah, these were some of the things I was thinking of talking on. And I won't even take this off of PowerPoint mode, because I'd rather jump into the product and show you that as well.\n\nBill Karpovich  2:46  \nYeah, so Well, I think these steps are, I mean, these topics are good, so it gets a sense of kind of how you guys think about this market. What I think is interesting and love for even if you and I, you know, get a little bit over some ground from from Friday to hear Dan, hear about it, and then obviously, this kind of your your kind of provocative view. Obviously, there's different different camps in this world, but this idea that task mining is is not needed or not essential, maybe. But you know that that kind of point of view around your your perspective and and then obviously we had this view on, you know, what is valuable within process mining, and we were a little bit like minded there, whereas it's not the fancy graphs, it's it's these other insights. But you know, you need to describe that in your words. I don't want to that also may get our quick conversation not hit it. So I love that point of view stuff. And then I think your view of the life cycle was going to map to your view of the platform, which I think is helpful. And then then I think we can dive in. So that makes sense to me. Okay, Dan, anything you want to prime Dan, or is it, let's dive in and it'll go where it actually goes.\n\nSoren Frederiksen  4:01  \nYeah, I mean, maybe that's just a little background on me. Came to Canada back in the 90s and actually worked on neural network. I was a new on the tooling side of a neural network company in 95 to a little after 2000 and did the tooling for neural network before neural networks kind of work. And then after that, we saw that wasn't really working. We were doing facial recognition. I switched into building software for 17 years for the casino industry. So if any of you ever go to Vegas and you get caught by the cameras there, like our face rack usually runs on a lot of these casinos, and we do instant reporting. So I did that for a long time on premise software, and five years ago, the partner I have now also James Henderson. He was coming out of a sale as well. I sold my company. He did as well, and didn't know what to do. And then learned about process mining about five years ago. So we've been in this space. We started the company about five years ago, and came to this from basically the perspective of James, run a company that had 1500 employees, and they would pay KPMG a lot of money to come in and look at the process, manually, interview people, and charge them a million bucks and give them report, saying you need to do these four things. They would fix those four things, and then nothing would really happen. Nobody would come back six months later and check if it actually worked, right? So he was the one that brought up and say, There's got to be a better way to do this. And we started looking into it. And process mining have been in Europe for almost 20 years, right? Created by Bill Van dalist, a Dutch researcher and professor, and he now is advising for salonis, which is the biggest company in the space. So we looked at that solonus was a little bit different beast when we started, and we started looking at different tooling. How do you do this? As soon as I saw process mining, I understood the theory. I thought, why the hell haven't we been doing this for all these years? Right? It's really funny. And if you look at this. It is so simple, because you take any data you have and turn it into three data points, which is a case ID for your support ticket, your P to P order or whatever, and then a an activity and a time, right? That's all we need to now do all of this stuff that we'd be showing so it's really funny, because it's very simple, all this stuff. So saw that happening, said, Let's go to we go consult. What do we do with this? And at the time, there were two companies that were just purchased, well, just after we started actually mine it. And the other one is path now, that was bought by solonas and Microsoft for like, 100 and 20 million at the time. So there was a huge amount of interest in this space. And we thought, I mean, I'm a product guy. I've always been so like, let's try to build our own because salon is so expensive and out of reach for most people. And it's, it's super good tool, but very, very technically difficult. And then there's, I don't know if you've tried any of the tool, the lowest end tool you can buy, which is super good, is called disco from a company, and they build a tool. The problem with their tool is, as soon as you could get up and running, and I learned process mining on it, but then it doesn't scale into industry. So you can't run it overnight, you can't automate it, you can't do other things. So it's a research tool you can use on your laptop to figure out your problems on your data, but then you can't send actions every day, right? Or start agents now or something else. So we wanted to build disco, but for enterprises, right? So we wanted to build a tool that was super easy to use. You don't have to be a nerd to use it, and you don't like we were trying to get a really low entry to people, and you don't need the price point of salon is also which they're like, a huge, huge price point. But we still want an enterprise. And I think I told Bill is, like, I've been doing software for 17 years on premise. I never wanted to do on premise anymore. So we did SaaS only starting out after two years. Half of our customers want it on premise, because we start selling to hospitals and banks. So we rewrote our architecture, and I'll show some of it. So now what we do actually is one of the things, we have three models we deploy in. So we have a cloud version that's multi tenant, and we actually deploy exactly the same model on premise for customers. So everything we do, and everything we do, and everything is showing today, you could take it and put it on premise, because the hospital we deal with, we're just installing a bank where their servers are not even allowed to be on the internet. They can't be online at all. So there we have to go on premise. And because we're a smaller company, we can't have multiple versions, so it's the same that runs across those. And then we have a desktop version, which is kind of disco, but just a little bit better, because there's a significant amount of money with researchers on their own laptops, that just runs on your laptop on there. So this is kind of how we see it. And our biggest differentiator now from our stuff, is on premise, because nobody really does it anymore. Apromoch had some which are off the game. IBM has a little bit of it, and they will do it, but they're IBM and like a massive company behind them, but none of the other vendors. Everybody is cloud, even salon is the biggest one. They don't support on premise anymore, and it's just become a big kind of business for us on doing it. So again, I'll just jump around a little bit, because I want to show you the product. I don't know. I find it easier when you see some of this stuff. And actually what it is we end up building. And so it is a what we build and what we use most, like, maybe half, maybe no, 60% are probably in cloud. So this is our cloud version that runs and you can access and we could set up a tenant for you. Can try this out if you want, but it's the idea of this is we do have the fancy graphs that you can do in process mining, where we take your data and turn it into these graphs, but it's not what we use the most. We don't typically use this. We use them for demos, and there are some insights you can glean from it. What you use is the technology that kind of behind that graph, right? Because you can do a lot of calculations on the graph. So if you see any of the vendors, most of us can do this, and you can zoom in on the graph and saying which steps happened before others. And then you can calculate how much time happened, right? And maybe to explain how we get here, right? Like, how do you get to this map, and how do you do any of this in process mining? And just stop me if you've heard all of this before, right? But if you have SAP, for instance, and you're doing P to P, because it's a simple process, purchase orders, there is one table that holds all your purchase orders, and that's either at line level or the purchase order level. That is now your case ID you have. So you go and grab that table, and then you tie that into saying, Bill entered a purchase order here, and then Dan approved it here, and then you received your goods here. And those are the activities, right? So you take a normal table as an SAP, you convert it into a format we can read in this tool, and then you upload it to the tool, and then nothing else happens for us to generate this, right? If you have those three fields, we can now just algorithmically generate this, and then you can See all the insights of how your process is flowing.\n\nBill Karpovich  11:40  \nThe key things in the Salesforce world that we've seen. The\n\nSoren Frederiksen  11:43  \nother thing you can do is you can see the variants. Right? Variants are, how many ways can you do my process? I mean, they think they do it. Always this way. Of these six steps. I always follow these six steps. But in reality, it's really like there's 1000s of ways typically a process is done,\n\nBill Karpovich  11:58  \nyeah, because how do you so, just just that, I'm just curious, you know, so we have seen very similar charts to this, right? So when you, when you look at this, this situation, and the what's, what's the technique you guys use to reduce this to signal, you know, because it's always like, Oh, really cool. It's not unlike the other things. But how do I, how do I reduce this to signal and and then how do I map it to some canonicalized view of of the process? Because even though there might be all these variants on the way, just based on the way the stages are set up, the reality is, there's, there's a superstructure this process that lives above this. And I'm just curious how you think about reducing to a higher level view of it that might, you know not live in the data, because the data was defined at a very stagey level. There's not this notion of kind of an aggregator. Yeah. Anyway, just just just curious. It's based on all of your expertise. Love to hear you, you know, kind of talk about that topic.\n\nSoren Frederiksen  13:04  \nSo basically, how do you make sense of this mess? Right? It's kind of, yeah.\n\nBill Karpovich  13:08  \nThat's a shorter, way more succinctly, yeah, yeah.\n\nSoren Frederiksen  13:11  \nAnd then the biggest thing you'll see in all demos, and it's really stupid. You like do this, right? And saying, Hey, look at how, look at how cool our software can show you this. And it has no meaning. There's no meaning. So What? What? What we do? And so there's two things, and one of those things you're asking about in process mining is called conformance, and it's where there are not you have a process and you think you're doing ABC, and then you can check how conforming are you to doing it in that way. And there are different ways. One of the ways is you can create BPMN, which we have, like, an editor for creating the process flow in BPMN, and then you can compare BPMN to the process and saying, wait a minute, you think you're doing this. Here's where you deviate. We haven't done that. And on purpose, we haven't done that because most companies are not even good enough to draw BPMN. You need a team, typically for that, and you don't have it. So what we've actually done, and now it jumps into something else, but we have something called log enrichment. So after we generate, as you probably show the chart, but after we generate your log, we can now enrich your log with different calculations, right? So we take your data that's coming in, and we kind of make custom attributes for this. And one of the enrichment is we have is for this conformance bill. So what we have found a lot easier and with these seven questions that are basically asking you as a business owner, and we would probably step through some of your variants, we would take some of the variants out, and we would ask you, it looks like here you are paying before you're approving. That's probably not good, right? So we sit down with you and try to generate rules for things you really don't want to happen. We can. We can bring some of them to the forefront and saying, wait a minute, in normal p to p, you shouldn't be paying before you receive your goods, right? You should receive your goods first. So all we would do a go in and set up rules here, where you're saying things should happen in a certain order, for instance. So if, if this, this admission, came before this other one, we could create a rule that does that. So we've actually found that this is a, we call it negative conformance, where we basically going to say there are things you know that shouldn't happen that are worse than others. So we set up these rules, and they will then trickle through. And I don't think I have a demo of it, but they will actually show up on your process map. So if there are activities you don't want to happen, we can color these things, for instance, but we can also calculate based on them later and and I think that's how we do most like, that's a very general view, but most of the times we will do things like this. There's lots of templates, and I can show you that will bring some of the problems to the forefront, and then that's other things we can do. So I guess that's the problem with like, getting to all of this. Does that make some sense? And how we make sense of this, that would be one of them.\n\nBill Karpovich  16:07  \nYeah, the enrichment concept makes a lot of sense. And like that idea of hunting, hunting backwards with rules. And say, if these rules were in place, what would have happened, or what's the Yeah, that's a that makes sense.\n\nSoren Frederiksen  16:24  \nAnd you can see here, right? So in this data, for this, all this, we can only show dummy data, right? Because we can't show clients data. But so there's only 106 different variants here that's showing in the bottom. And you can see the top one. In this case, happens 2020, times, and then all of a sudden, it's very few, right? So you only really need to go through the stuff that happens a lot the bottom one. So there's a lot of frequency filtering and all of the stuff we do and saying, if something you do once every two years, we don't really care, unless there's a real compliance issue, right? Like you do something that's illegal, so you very much filter it on that, because it's hard to and the other thing you do is you figure out, of all these steps we're showing here, which ones do you really care about? Because a lot of people will do so when you when jumping a little bit. But if you do a project, when you extract this out, right, you can find 10 activities or 200 activities, depending on how much we do. Typically, we say, start smaller. So we had customers that start really small, three or four activities, and then they find out there's a big gap between B and C. And this is the talk of whether or not you do task mining. Can we find more steps? Right? Can we find the steps that are in there? But we say, don't start with 42 activities, because it becomes a mess that you don't need, and half of those activities you are not in control over, you can't do anything about. So why even show them? Right? We're very much when. So what we end up with here that I showed is a dashboard. Nothing should go on this dashboard if you don't take action on it, right? So when you show a customer dashboard of any kind with their process improvements, then it should show some numbers on it. But maybe I should try to get back to a little bit. I think I lost a little bit of where we were. But let me try to get back a little bit and show you. Because if you look at the if you look at the project life cycle, right? If you look at some of this, there's a couple of things to it. The first thing, and I forgot to show it here, the biggest thing is really the buy in from the company, right? Why should we be doing this at all? We've done way too many proof of concepts for somebody who was just kind of interested, and we found the things for them they wanted, but then they didn't know what to do with it. So the process projects should always start with it could be an investigation and see where we have problems. But my shipment is too slow, right? I want to make that better. We have too many returns. Why is that happening? And why are the returns taking so long? So it's usually, it should always be a business problem. It's the biggest thing that should happen up front. Then there are kind of three phases in it. There's a data acquisition where you're going to go to the ERP system, pull out the data, then you analyze it, which is really our tool, right? We will do the analysis. And then afterwards, you say, Hey, you had this problem in shipping. It's all about your approval process too slow. Somebody has to now go in and consult and actually make the improvement in the company, right? What do you now need to do to improve it? We do these two stages, mainly, right? We don't do anything about fixing it, like consultants we work with will do this, yeah. And, and\n\nBill Karpovich  19:36  \nthat's, that's our core business model today, right? And, Soren, you mentioned a couple of the pain points that the customers might come to you with. To what degree are they asking today? Hey, how can I use AI to reduce by, you know, process, cost and XYZ area, by, you know, consent and am I, you know, with every CEO asking about, you know, where they're going, even the benchmarking, like, okay, like, if I have a sense of where to look, this is great, but how do I know if I even need to look?\n\nSoren Frederiksen  20:15  \nThat's the you asked about AI, because I know you guys do AI, right? But that's the so and again, maybe jumping ahead, but I still think it's better. So if you look at our product, we've had aI integrated for a long time into our stuff, and the way we do this also, because there's lots of different ways you can do AI. You can take a data set, uploads, chat, GBT, and you can ask it some of the questions you could ask our tool, but it has to write Python first to reduce the data, because often our data will be 10 million activities, and you just can't put that in, like not even Gemini. So what we do with some of that bill is, and there's lots more you can do with AI in this there's, there's a few things you can do it. You can help the analyst ask questions about their data, and that's one thing we do fairly well.\n\nBill Karpovich  21:02  \nShow an example while you're on the Yeah.\n\nSoren Frederiksen  21:04  \nSo, what can I improve in my process? So, and the way we do this, because also this depends on the model up here, and I'll show you we do this with this is currently done with open AI, but it goes through our servers because a lot of customers show up and they don't have anything. So this would just list a bunch of things, but it turns it takes the data that we've already analyzed, right? So we upload their data, we run templates against the data, where we know they want to ask about bottlenecks, like the standard things you can do with process mining, and we actually feed that into open AI like we kind of pre feed it in. We call it base knowledge, and now they can ask questions about it, right? So, and we do this in two ways. We either do it like this, but we also allow you to schedule this overnight. I want Monday morning to send this report to bill in an email, but only focus on what happened last week. So that's something we've done, and it was something we'd hope take off more. There's some problems with llms. Some people don't trust them. There's lots of problems with people are not allowed to be in the cloud. So because you are AI, we, what we actually do is we integrate. I have to jump into another one. We integrate with on premise, llms and pretty much all the vendors. So we can, we can set up the large language model people want to use in our stuff. So if I go into the settings of kind of my tenant, I've set up open AI LM studio, which is a local open router, and then I can use different models asking the questions, because the models are fairly different. So the biggest thing we do right now, and the main thing we do here, is integration to ask questions about your data. That's the big thing we are working on, which is a huge benefit, because if you get a new custom data from a client, and you are a PWC or entity that we work with, often, they don't some of them are very experienced, and they know how to deal with that right P to P they know how to deal with a new one. They don't large language models are very good at laying out the scope. How should I do these analysis what are the five dashboards I should be showing in a P to P demo for a hospital demo? What should I be doing? So there's also the analysis side. I don't know if that answers your\n\nBill Karpovich  23:33  \nquestion, yeah. So you guys, you said you guys been working on with aI mean, guess today's the three year anniversary of chat GPT, or somewhere, maybe not today, somebody somewhere close. How long ago did you guys get it into your product?\n\nSoren Frederiksen  23:49  \nAnd go ahead, almost six months after chat GPT came out, we put the first version in. And the bigger problem in the beginning was that you couldn't feed it a lot of base knowledge right? The context window wasn't very long. Now they've gotten so much better. So in the beginning, it was much simpler questions you can ask it depending on the model you have now, and that's why you can switch our model up here. And you can say, I want different models, because it really depends on some combat so much quicker. So, but where we actually see that better benefit is actually well for the analyst, this is helpful, because I can get an overview, and I upload my event log, and for the first thing, the way we did it before large language models, where we have a bunch of templates, so you add your data in, and then we have all these templates that answer standard questions for you, and you can add these, and they will just automatically throw in different things that you could do, different mainstream behavior you could see, yeah, right. But now the good thing about since we have these templates, we can take all of those, and I need to go back and show you, but all of ours is built with notebooks. So we built up this string of notebooks that have little blocks on them. We built up and all of them can convert the visual prettiness into something an LLM can read. So all of them can kind of speak LLM. We can output JSON or some other format to the large language models. So they can read over this for you instead and say, Hey, Bill, this is your problem with your your process, which is, and we do that in two ways. We do it in the product, but we also allow you, we have actions where you can do this outbound. So this is probably what would be interesting to you guys. We can take any of these calculations, send them out, and let you write Python that can then do whatever you want. So you can, you can kind of lose our product without maybe even needing this, right? But it just it used us as an engine to feed into it. And maybe, maybe you get back there on showing, if you look at how we build our things, our architecture, a little bit, and if you look at how you do projects, and this was the big problem with like socelona 's. Can do this stuff, all the big vendors can, can be part of a pipeline, right? How do you become part of an organization? Because running process mining for analysts are not very interesting. It has to become part of the organization 's day to day life, right? We want to send you emails. We want to integrate with other systems. Otherwise you are a data analyst, nerd tool that sits in the corner, right?\n\nBill Karpovich  26:26  \nAnd how does that mean? Trans becoming a diagnostic tool? This is, you know, one of the big questions we've been wrestling with, right is, you know, one time, diagnosis is interesting, but you know, you tough to make money and tough to build a business that way, and you're never going to get the benefit to the client, because it's going to be a journey, not a not an event and and so obviously, having this reporting and having action hooks and is all about kind of getting to the operational, ongoing, continuous improvement part of the life cycle, how successful as the industry been getting there? And how about for you guys?\n\nSoren Frederiksen  27:08  \nNot good enough. If you look at most of also, if you look at Salon 'storm track, which are, like the biggest part of our industry, right? They don't almost say process mining anymore. Either. We won't go out as a process mining company. We'll say process intelligence more than anything, but most of what salon is does is not operationalized. They would like it to be, but it's not. It just hasn't gotten there. And I think it's because they didn't. They came out of academia, so they did all these projects, right? And if you were to look at a typical project, people still like to do POCs. We hate them, and we try to stay away from them, but we have to do some of them. So if you do a like a proof of concept, it's a one time deal, and you figure out, yeah, your process is slow doing these things. We try for all of ours to get in and integrated. And I know you do hospitals as well, right? So maybe I can show it with an example. Bill, I think I have so if you look at a hospital, for instance, I think, is this my Yeah, inpatient discharge, right? You can, you can write dashboards. So you could do a command center dashboard that tells you things, how many are admitted, and just numbers from your system, right? And you can do this historically to find the problems right. And then what we actually have, and we have this running in a command center, and actually in Riyadh Hospital in Saudi Arabia, where they run this view in their command center. And this is what we'd really like to get to, where you basically break down your admission into stages. And then you look at because we have all the timestamps of all of this stuff, right, we can now say,\n\nBill Karpovich  28:48  \nlet me make sure I just understand this. So it sounds like the approach in here is, yeah, you have operational systems, but typically their dashboarding and their ability to create context just is not great, right? And then step one almost, is just having a better dashboard. And it's a dashboard that has time sensitivity as as trending has, you know, whatever the enrichment is that you guys have caused this to happen, and you're creating a visualization that can be updated close enough to real time, and is operationally valuable enough that you become part of their operational desktop, or at least the management 's desktop. Is that the right understanding of the chain of connection?\n\nSoren Frederiksen  29:30  \nYeah, that's what, that's what we would like to be in most of these scenarios. Because if you do these proof of concepts, there's like a year between you do a proof of concept or something, but it it takes you a while to actually get between new like new new projects. And if nothing happens in the business, if they don't take action on and it can happen, right? They do analysis once, and they go offline, they go fix something to process, and they go back six months later, and they do the same analysis, right? Which manual we have a huge, actually, a insurance company, and they do life claims. And one of the big problems they have had, they have these Nigel forms. They call them, not in good standing on death certificate, death orders, and they just didn't know how long their claims took. They didn't really have any numbers on it. So they're trying to figure out if a client submits a death certificate, like a death claim, but their form is not in good order, they have to send it back to them. And that was the process. They didn't really and it adds a lot of complexity in their business when, when it takes too long to pay out a death, death claim. So they're actually, they're currently still just doing it manually bill so they will, because they have a lot of problems integrating our stuff with their on premise for security reasons, right? They they're not allowed to. So they're, they're uploading every, every month they upload a data set, and she manually updates all their charts and graphs and gives to people. But, and we've just, we're just talking with them, for instance. So we have also, we have apps in everything we do. So you can, you can set up dashboards, but we also have apps you can run and so you can take, we have the platform for the analysis. They work out all of this stuff, and they set it up, and they click things manually. But then afterwards, you can create your own app where you say these dashboards are now important for this role. So you're actually allowed to go in and say, Dan needs this view, Bill needs this view, and we just give you a login, and it's basically, it's setting up a bunch of favorites for people, but now you can see only some of these things, but it still means you you log in and check this out, and this is, for instance, what runs in a command center. The command center wants to know what's happening right now and also want to see what happened during the day. For instance, they would set those up. I\n\nBill Karpovich  31:56  \ndon't know. So I don't\n\nSoren Frederiksen  31:59  \nknow if you want to know how we do some of this, or if you have other questions on\n\nSpeaker 1  32:04  \nsorry that those would be my question is, like, if, if we had, like, a mutual customer, stick with healthcare, if that's most comfortable, what what needs to happen On the customer 's side to start this process?\n\nSoren Frederiksen  32:22  \nSo if you look at and then, so the biggest problem is always the data, right? So if you look at here, like a whole bunch of different ways, you can commission and get the data out. We have two kind of main projects. The one I've been showing so far as we call minds of studio that does all the analysis of all the data, but 60 to 80% of most projects is actually getting the data right. How do you get the data from their source system into the and how do you transform it right there? So there's two steps in that. It's getting access to it. First of all, for you, do they trust you? And then the second part is actually converting it from those tables into something process mining can read. And our data designer does this. It runs a bunch of SQL queries. It uses AI to write the SQL queries. And then, if you're like, if everything is on premise, which this one's showing, it means they have an SAP database. We put the data designer in, and we push the data into minds to studio fairly easily. And then we just schedule this, typically, to run daily. For a command center, they might run every three minutes, a smaller subset of it. And so this is what we want to get to, that it runs every day. What we often start with is they don't trust you. You're new to the client, so they don't want to give you data access. So they show up with CSV files, and we just upload the CSV files, which are from the database, and still use our data signer to convert that into data. So this is, to be honest, the biggest kind of hurdle in doing process mining for a client, you have this upfront. They're not going to really pay for it, because they don't really know what's happening, almost, and you don't see this. But you have this data transformation you have to do upfront. That's kind of the biggest cost of process mining, is I gotta do this. And if I do it to SAP, and I've done five saps before for P to P, it's easy, right? But if you throw me in a totally new process, I don't know what. I don't know the schema of the database. Now I gotta figure this out. And databases are never documented. They're you're on your own, and our data designer actually will do this, and we have a co pilot for data science, so you have to write, you write a query for every activity you have. So every, every time, if you look at this more time, if you go into the database and there's a timestamp in the database that is usually somebody doing something right? Dan updated the record at this time. He closed it. You received the good at this time. So you write a query for each and then you transform it. So if you do a proof of concept, you could do it with CSV files. We try to normally get access to the database, yeah, and then we do the transformation, push it in, and now you have the data you can analyze. And typically, then it starts with a historical view, so you go back to them and saying, and this is where it's really good. We have a lot of consultants now that use this to show how bad their process is. To really get to after work. If you're going to look at anybody 's process, I don't care who it is, you can always find flaws, right then? How big are they? So they use this very much to go in and they open up and say, You know what? You have all this rework you're doing, like you keep doing the same activity over and over as a common thing. Or the duration between these two steps are so long. Why is that? Right? That's the and\n\nSpeaker 1  35:37  \nwhat, what's, what's a common observation or mining period before insights tend to arise. Yeah, so\n\nSoren Frederiksen  35:49  \nwe, I mean, I can talk to one we just did in Germany, for instance, we did one for a large train company. They they lease out trains, and they just understand the size. They repair about 68,000 wheel wells a year, right? So they own the trains, and they lease out the trains to the government and other people on the train tracks. So their big problem was that, how do we not have the trains in the shop? Right? As long as they're in the shop, we make no money off of them. And so we were looking at their procurement process for all of that stuff. It's so in that process, it was a purchase, like a proof of concept, and it was run by taxa consulting, right? TCS consulting ran the project. The problem they had is they hadn't gotten they hadn't asked enough to get data access. So we spent a lot of time just getting access to tables. They had four customizations in their data that we had to understand first. We couldn't get the experts. So it really depends on how much access you have. So I think we spend about four weeks getting the data from theirs to our system, just getting the data and then analyzing it was less than a week, okay? And the outcome we then had, because it was very like, once you format it. I mean, the way we set up all of our stuff is clicking and like, it's no no coding, right? And we try to use templates and processes are very much the same, like different nuances. And what we found there was, like, we showed them that these three steps cost them 30% on their wagons, which, like my partner then calculated into this cost you $2 million basically a month to have these train direct because of these two processes. So do something about these three steps. And then the consulting company came in and said, these are the things you could do about it, right? But so it was really one dashboard with like four numbers. There was the outcome of all this, but it was kind of the savings for all of the stuff on the outcome. So but, and we did that, but we did that with CSV files, which is a huge problem also, because the people exporting the CSV files didn't know how to do this properly. So if you don't do it correctly, you can't import them again. So if you don't, for instance, if you put a comma in a CSV file, and you don't, technically do that right, the whole thing breaks and you lose records. So we spend a lot of time on that process. So the better you have control over getting to this data, the easier it'd be. It becomes okay?\n\nSpeaker 1  38:18  \nAnd if, if there is a process that spans, let's just say, like SAP and Salesforce, for example. Does the data designer needs to be connected to both of those, or is there some way that you guys have figured out? Yeah, if part of the process leaves a system that we're monitoring. No big deal. Here's how we can still gather insights as a result.\n\nSoren Frederiksen  38:46  \nYeah, so there's two different ways you can do it. Depends on if it's two different processes that don't overlap. You can do it as two. So I don't know, does my architecture show this? I think it might show on here. Yeah, it does, actually kind of so when we put stuff in, you put it into data sets, right? So once you converted it into an event log or a data set, that's now one set of data that could come from one source, and it can also technically come from multiple sources, one data set, but if you have one data set, so what you can do is you can add two data sets. You can enrich both of them you can create these investigations, which we do, which separates more logical things? I want to talk about Europe here, or us here, or this is for my daily process. This is for my historical and then underneath these, we have these analysis. And then the analysis can then get thrown up on a dashboard, but you can take two source data set and put on one dashboard. So one way you could do it is you could actually extract it separately and then join it back up on one dashboard. But it's two different processes you're just showing in one place, right? You could do that. The other way you can do it. And I think I can open our data sign. I should be able to let me just log in. I can also, if I log in again, you can kind of see I have access to quite a few tenants. So this is our tenant bill. I know you asked for it, so we have multiple tenants on but if you go in and look at our data designer, I think I have demos in here, yeah. So this was actually the company we worked with. But can I show? Got more data? So this is what the data design and look like. You have a case attribute query that that finds all the case IDs, and then you have a query for each activity. And these are very small. So the SQL is not very difficult here. It's really just and then it compiles all this and puts it together for you if you want to connect to different data sources, right? So you can, you can connect to a DataSource, and you can have multiple data sources in one extraction. So you could connect to two different ones, these are kind of the ones we connect to now. So you could technically select multiple these sources, and we can pretty much do anything that has a database behind it, right? Because we can write queries against everything. So if you give us an ODBC database from SAP, we write SAP SQL. If you give us a database from, yeah, from So Microsoft is common one, right? We write what's called T SQL, and you can have multiple of these and write different queries, and we just join these together and turn it into an event log. So what this means, Dan, is you means you have to have a SQL database. We currently do not connect to REST services. If you look at somebody like salon, and Salon has forced you to put all your data in their data warehouse, and then you extract from there, right? So they own the data warehouse, which makes them things simpler for them. We don't like to. We're not data warehouse people, right? That's not our job. So if you have something in Salesforce, for instance, they don't have a query language, right? As far as I know, you can't really query it. You can't go directly to the database. So there's a rest. So you'd probably have to move some of that data into a queryable location to use our tool or write something else to pull it out. But you could take multiple of these datasources and combine them into one dataset. So you could put four activities from this and then four activities from Salesforce, and then four from somebody else. If you want it to okay. It doesn't. It doesn't happen that much, though. It really doesn't. And I think that, because the biggest thing we talk to people about when we do this, find three to six activities. First, pull it in, and the data sign is very easy to run it multiple times. Find these three, write this three simple queries, pull it in and look at your data, and then you find out, you know what to answer any questions we're missing between these two steps. And now you go on, you find things in those steps we've seen, especially work. We work some Indian consulting companies that went out and they got 42 activities, right? And now you're sitting there with a pile of mess that you can't really figure anything out, because half of the activities you got were not critical, right? When somebody updated a record is typically not important unless you know why they did it. For what reason did I go off track again?\n\nBill Karpovich  43:13  \nSoren just back to the point on the data extraction while we just to drain it. So you know, certainly the task mining piece is a compliance rat's nest, right, in terms of getting on people's desktops and and getting them convinced on all the different ways that it's safe, even if it's they can get through the social parts of it, on the data side of it. I mean, it's gonna be on the process mining side of it. And you showed your spectrum of support, which I think is wise, right? So everything from, you know, kind of sitting inside their firewall with the letter, yeah, we're sitting outside the firewall with SAS, or say, and, you know, so there's a bunch of different compliance realms that get triggered, right? So if it's Hey, I'm taking it off, off of my network, that's going to be the network security consideration. They're all kind of, you know, obviously work together, but different enterprises will have different sensitivity. So in the case of hey, if loans doesn't leave my my my network, fine, as long as you can do it inside of my DMZ or inside of my firewall with your local version. You know that? Can you know, if I think about all the different traps that can be set compliance wise, and how to get through that gauntlet most readily, just curious what your experience tells you right then, of course, there's the CSV data. Hey, fine. You don't have to have system access. And if you do your analysis inside of my firewall, great. But if you do it outside of my firewall, not great, just in the real world, given your experience, how does that unfold? And do you need a Swiss Army? Because you never know, and you're going to need as many options as you can. Or is there a particular pattern? It's become clear.\n\nSoren Frederiksen  44:53  \nYeah, this shows pretty much all the ones we do, and once we find is needed. So the one we like, the best bill, is the one here, and that's basically everything run on our SaaS servers. And to go into their database, they open a port here to go into whatever database it is, Oracle or whatever, and then they whitelist our servers, right? And that means we can access it. We get in, they set up a read only user where we have access to only\n\nBill Karpovich  45:18  \nthis obvious, obviously for you, it's the best, yeah, but\n\nSoren Frederiksen  45:22  \nno, but let me explain the sort of the problem with that is, security wise, is not really a problem because it is locked down tightly, but it's hard to convince a lot of IT companies to do that, sure, right? It's very difficult, don't\n\nBill Karpovich  45:33  \nthey also do then sock two audits on you everything, and data retention strategies and like, what? So what comes with that?\n\nSoren Frederiksen  45:38  \nYeah, we are SOC two certified. We have to be. We can't be without it. The problem with that is they now have to be good at narrowing down your user access into their database, right? Yeah, sure, yeah. So there's lots of so that is what we try to get. Half of the times we don't get this right, or more. Then the other thing you can do is, if you go everything on premise, that means now they're maintaining all the software, and that's what we do for banks and we do for hospitals. The problem with this is you as the consultant, or if you were that, lose control, because you have harder time getting through their analysis, and you have harder time getting to their\n\nBill Karpovich  46:17  \ndoes this look like get me a VM or get me something in your container farm? Is that what it\n\nSoren Frederiksen  46:22  \nlooks like we run off of Windows VMs. A bunch of reasons for the historical but, yeah, if you have a virtual machine with 16 to 32 gigs of RAM, we can run on it for like a modern Windows machine. And we don't, we use SQL server as well, which we can install on the machine. Or you can use a enterprise SQL Server. So installation is actually pretty simple, and now we also we completely support that. You don't have to be online for updates. You can do everything in a completely closed box. What happens a lot and where you like exactly what you asked. This difference. So if we put the data designer, which is the piece that does the extraction right process mining rarely needs personal data, right? The most personal we ever get is your name, and we just as well can get your custom like your employee ID. So if we do this scenario, it does mean that data design becomes more difficult, because I now need a VPN into your servers, or I need to be on site, right? Because very rarely we can give them. We have packages for SAP that we could give you, but there's almost never two that are exactly the same, right? Unless you find an industry that has the same provider and it in Salesforce, and you'd always do the same. You could, you could do this, but there's always customization. So doing this, you now need to be on premise. We have a guy that's doing this right now for a hospital in Ecuador, and he's actually taking a laptop on premise with this, doing all the work for the proof of concept on their premises. But now it's okay to push up to us in the cloud, because you're taking very little data, and they can see what data is getting pushed up there. So we, we find much less resistant with this. If they're open to cloud at all, right? If they're not open to cloud, it doesn't matter, then they have to do this option up here. So this, we found Bill a lot easier to get through security, because they can see what we're pushing and we're not opening inbound ports for their stuff. If you're if you're if you're going into Salesforce, though, it's almost the same where this is all just in the cloud, right? Yeah, because, yeah, so and we do, we don't have a connector for Salesforce, because it's an API, but we do have one for snowflake, for instance, which is also a cloud provider. So\n\nBill Karpovich  48:41  \nhow long does in the real world, the customer says, hey, I'm interested in this. How long does it typically take to get through the compliance process? Whatever the security pieces are, what's your experience?\n\nSoren Frederiksen  48:55  \nSay it's so it's been all over the map. Our insurance company, which is really regulated, they took two weeks. But that's because they bought in very small no data connection, no data access. They create their own event logs and upload them, so there was very little commission. But we had Motorola, it took us, what, 12 months, I think, to go through their security.\n\nBill Karpovich  49:17  \nThe PII argument is pretty good one, right? I mean, there's no, I mean, there's really no reason why you need PII.\n\nSoren Frederiksen  49:24  \nNo, there, there isn't. There isn't. There's very little. I mean, it is really nice to have names because,\n\nBill Karpovich  49:30  \nlike, account data, like, normally, if you're, like, your your P to P, example, it would be interesting to know that. Oh, but, you know, accounts in and in the US for the ones that are causing you the problem. So you got to know, like some industry data may be, hey, and by the way, it's GM who's causing your problems. Is that considered PII at that level? And is that relevant? Or is it typically happen at our level?\n\nSoren Frederiksen  49:55  \nNo, but it is sensitive. So in purchase, like we do a lot of financial because they're in process mining, they're not, they're not the most interesting. And we're trying to do a lot of others that are more interesting, but in that cases. So if you do AP or PDP, you need vendor, and you need, you need numbers, right? So if we go in and we get some of the client to do this, we know how much they sold last year, right? Like, if we have so by the way, also, we work in two different models, either they allow us into their to their tenant, because they want help from us, right? And then we can see the data, or we can be cut out, and then we run we have no idea what they're doing on our servers, but there so that is sensitive. But it's not PII, right, but it's, it's sensitive data to obviously know how much total sales they have, or how many invoices they have, but it's not PII what we do a lot Bill. And so because we are socks who certified, we don't have any. And that's the other problem. If we recommended or sold a data warehouse, we would trigger a secondary vendor in our that. So the sock becomes a lot more complicated for that. So being a being one vendor is easier, being a smaller vendor is harder, because we're not as big. So for us, it's much better to come in with consulting houses, because now they trust, they trust TCS, and TCS have said they trusted us, so they like it makes it easier, and then we just provide then, in that case, we just provide them our documentation for being SOC and PCs guarantees it or NTT, and then it makes it easier for us, but it is always a getting to the data is the biggest hurdle. And I'd like, I haven't even shown you much doing the analysis is comparatively fairly trivial. So if you're thinking of doing all of stuff, think about, where are you good at it? Where can you get the data? Where do you know the data? Where do they trust you with the data? Because if you solve that, you're a lot further ahead. So maybe I should just show it. If you want to do analysis right, we build up the way we build up the analysis. Are these blocks we put on the screen. So this is built after something called Jupyter notebook, which is basically you have data coming into the top of a notebook, and then you put different blocks on there, and you manipulate the data. And so we have two blocks. We have filter blocks, and all they do is this one, for instance, remove the cases where the activity name is patient departure. So you can do filtering. And you do filtering by just clicking here add. And then you select one of our filters. Seven of our filters account for about 80% of all the things you want to do. So cases like this filter would filter find me all the vendors called Coca Cola, right? Or find me all the vendors in North America. So you add these blocks on our notebooks, and then the filtering, and then you add visualizations, which we have 73 of where you can do counts or grids or breakdowns or the charts that you see. So as you're doing analysis, you're basically building these up and where we make it just easier. We have pre built all of these final ones. So if you add any of these, we just built the blocks for you. So, so when you get the analysis, it's fairly easy to the biggest problem with the analysis part is, what the hell am I looking for? Right? What? That's a big problem. I get all this data, where do I start? And that's AI is really good at kind of helping with that. It can see, we'll give AI all of the data in the breakdowns. That's normal for process mining, and can guide you along the way to say, Yeah, you should probably be looking at the rework, right? So we have a for instance, in here. If you want to look at rework, we have a rework template. Let's see how it does on this data. So if you add this template on to your data, it will show you likelihood of repetition. So this doesn't cases with activity repetition, but it will show you which ones are repeated the most. And so medical administration adds 17 days whenever you repeat it. And it's, this is how many repetitions they did in this data set, for instance. So we have all these templates you can add, and then the AI can also look at this and kind of help you along the way. So, so, so building the analysis itself is not difficult. Knowing what to look for is kind of the more not, I wouldn't call art, but that's where it takes a little bit experience, right? What could I find\n\nBill Karpovich  54:23  \nif you, if you click the help button on your AI button over there, what is, what is that doing? Just curious.\n\nSoren Frederiksen  54:29  \nWhat? Oh, this one, yeah, something we actually just playing with. It just tells you what you could what you could ask.\n\nBill Karpovich  54:33  \nLet me see if I can make this bigger. Okay, so that's more\n\nSoren Frederiksen  54:36  \nthe help. Yeah, this is a hard coded thing that just comes up and yeah, just some common questions you can ask, yeah, yeah, okay.\n\nBill Karpovich  54:47  \nSo see where okay, but it doesn't sound this seems like okay, got it.\n\nSoren Frederiksen  54:54  \nSo I think what's what I what we found, is interesting. And if you look at the structure a little bit on it, I'll go back to the chart. So you can put data in manually. You can put it in through our like we have an API, so you could also write your own code, take it from where you want, and send it to our API and create datasets and update datasets. So there's a few people that do that as well. So and we have APIs that you can access by tenant and so forth as well for our enrichments. And so what we did when we designed this is we wanted to be no code, we wanted to lower the entry, and then we kept adding more blocks for people asked for more things, right? And then finally, like, we can't add a block for what everybody wants. That's the problem with no code, right? You run into things you can't do. So what we did is we actually integrated Python in a couple of places. We said we'll do 95% of what everybody wants. If you want to do anything else, you write Python to do exactly what you want. And we do the same on the outline bill. And this might be where things are interesting, because we can actually take any of the analysis we do and then send them out. One of the things we do the most where you don't have to code is every Monday morning, I will do an analysis, and I'll add a filter to my analysis on whatever the filtering is. I had to filter here somewhere. So I'm filtering anything that doesn't have departure this grid down here. I want that email to myself every Monday morning, and that could be my slow vendor invoices, it could be anything where people have done like paid before approval. So we do that, and that's without code. You go into this action module, and you pick the data you want, and then you take different steps. And the steps you can do is send an email out, for instance, and then you schedule this to go out, and the actions we have email is the most used because it's the simplest, right? It's very easy to email for but here is where you can take any of the data you select and actually write some Python to now do whatever you want you can do in Python. So we will run the Python on our server for you, but it could go and interact with whatever the server can reach right? So if you have, I want to push this to Power BI, I want to do whatever we give you all the data behind our analysis, and then you can go write this Python. So that's kind of how we've made sure that we can be part of a pipeline, that we're just not a like our own box on there. But see, we have all kind of come up in time and arena time. I don't know if did we cover most of it? Do you guys have\n\nBill Karpovich  57:30  \ncovered a lot? But we that I'm, I know personally, I could go, like to keep going, but maybe, maybe, if you're up for it, we can schedule another time you had the OEM opportunity here, what was on your mind there, that you wanted to share was really intrigued by the model, by the idea that us isn't important to you. Just speak to some of that and how you guys would think\n\nSoren Frederiksen  57:57  \nwe don't have one customer in the US. I mean, we're not really going after customers. We work with a lot of consulting companies, so TCS, but it's out of India, so the most of the consulting companies are actually off US soil. So we do have, and I think this has even been changed a little bit. So for all of the server, if two things we can do, you can either keep it on our servers and use that. But you could also install your own server, and then we can set up and you can actually change the application settings. So you can remove all the company information, you can remove the logo. You can actually set up your colors, so we allow you to change all the colors background, so you can kind of skin this to make it look like your own. And I know we have a demo somewhere, I think for PwC, but yeah, so that's the idea of it. And then our name is kind of removed from all of it. And then you just brought this human product\n\nBill Karpovich  58:52  \nat the highest level. And you're, you want to stay on the technical side, but if I was just You just beginning to think about it like, what are the economics of something like this potentially look like? Like, how do you guys price it?\n\nSoren Frederiksen  59:05  \nI don't really know. In the OEM, we typically pill price one analyst for about 10,000 a year. And then there's packs of users that don't quote me on it, but we'd like we do a five pack of users, because you can, you can access this as the analyst that can set up all this stuff, and then you can be the user that uses this afterwards, right? So we charge, typically, for those things. We don't charge per process in SaaS, we still don't charge for, like, how much data you have, because we haven't had any that are so big. So we, we try to make the pricing easier.\n\nBill Karpovich  59:38  \nAnd I think an average customer then becomes how much per year, approximately.\n\nSoren Frederiksen  59:42  \nBut it really, really depends, like customers between 40 to 250 Yeah, all right, we try to and cut. I mean, if you go into salon and 's right, they almost don't pick up the phone, unless half a million dollars, because they're so big, and the amount of value we have to find in a process to go in and charge half a million dollars is, is like, it has to be a massive organization. We, our best spot bill for companies is probably half, like 100 100 million to about a couple of $4 billion of annual revenue. It's kind of where we, if it's a lot smaller than 100 million, we it's harder even to find any anything you can improve for them. So that's, that's kind of where we play. And if it gets much bigger than 4 billion, we start being it's not something we handle as well anymore. I mean, we don't handle 100 million records a day, right? I mean, there's, there's certain limits to what we can do. So and OEM. I think with all of this, if we don't really care same price for on premise and cloud, we don't really care the cost of running this in Cloud is not massive for us. So, so if you go on premise, we cost increases for support if you're in cloud. I mean, we need to run the hardware right. But yeah,\n\nBill Karpovich  1:01:00  \nI wanted Dan to hear your comments around task mining. Could you just just talk us, given your expertise and living in this space, love your your point of view there?\n\nSoren Frederiksen  1:01:09  \nYeah, yeah. No, I we have it. We've done it. And really what it is is you basically track how much I'm I'm spending in the Excel versus how much I'm spending in the in the product. If you really want to do it, well, you should tie it into the case ID that you're currently working on. And if you have to do that, you would have to screen, scrape all of the different screens and figure out you're now an SAP, and where is the purchase order number and stuff that gets really complicated. So we've actually simplified and said, you enter the case ID when we track you, we are not the company that will sit in the background and look at you for 's and then do all of this. We think it's too intrusive. So what we do right now is we take you, tell the case ID, you go do some work, and it all ties into that case ID. We know all the applications you jump around in, and we can say you spend this much time in Excel, you spend this much time here, and the case ID now becomes part of the event log. We then upload this, and now we have these extra steps, and we just find that it's almost as easy as because really, why they want to know is like, how much time do you spend in Excel? We find it is so much cheaper and easier. Just go ask some of the employees do a bit of survey. I'm just, yeah, I'm not a biggest fan of task mining. I think it's intrusive. I often we haven't seen enough where we actually needed it. Some wanted it, but they they could have done it by just saying, You know what? We have the problem between A and B. Let's figure out what we do in there, and do that manually. So what we do also is we do actually allow you to estimate cost on your activities. And we use that quite a lot where. So if you go in and look at it's in our enrichment stage, you can say, this activity we estimated to cost this much. And now you can then use that to calculate on and then you can add up all the activities you did for that, and then that gets you 80% of the way there. So we basically put it into this, oh, I clicked the wrong thing. We put it in there so it makes it easier, and then you can now use it as a calculation. And we find that so much easier than task mining. A lot of companies don't agree with me, because a lot of people sell task mining. I'm just not a big fan of it. I know. Did that have any questions on particularly or I wouldn't. I wouldn't\n\nSpeaker 1  1:03:33  \nappreciate the perspective. And now you guys feel that you know you can accomplish your customers goals predominantly through process mining. Less, less is better, right? If we can still create value with fewer tools,\n\nSoren Frederiksen  1:03:51  \nwe've, we haven't had it enough, that's the thing, right? We haven't had task money that where they really wanted it enough to and I wouldn't, I wouldn't say you should OEM our task mining. It's It wouldn't be good enough. If you want to do task mining, don't base it on our product. It's just not good enough, right? So that's the other thing. Bill to it. It's just not it's not really what we want to do. So if you really need task mine for whatever you're about to endeavor, you got to find it somewhere else. I'd say we, like I said, we did it more to be able to check the marketing box and the feature box that we have it, but we don't really know.\n\nBill Karpovich  1:04:24  \nWe don't look. Is there anyone that you do respect in that space? Who, if we were saying, Hey, you guys could be a partner on the process side, XYZ on the task side, is anyone?\n\nSoren Frederiksen  1:04:35  \nNo, we actually, we work with scan, but there's semi strange company. They're pretty good at it, scan. Ai, there was just a slightly strange company. I mean, Microsoft does it really well, right? But, but there is such a big ecosystem, and they're hard to find out their products. They do process mining as well, but, and they bought one of the companies. They bought mine it they were called, but it's, but it's such a the problem with the big vendors is, like Microsoft, is, I produce tons of Microsoft products. Process mining is like a side project for them. So we know from people from mine it, and the product is not getting the attention because it makes no money for them. So they got a pretty good product that's in there, but it's not, it's it. You have to use it with their power platform, for instance, and it's, it's complicated, right? It's, it can do a bunch of stuff, but it's a lot more complicated. And so then I, but I don't, yeah, I don't really know, Bill, I'm not the right person to ask. I think, because I don't, I don't like it as much. So, and it is it. I mean, it's a choice. We keep talking about it, and partner and I if we should or not. But so far, we stayed away, actually curious, because I know that's what Ross asked me, also coming into this, right? Have you had somebody who wanted to do it or,\n\nBill Karpovich  1:05:53  \nyeah, I think you know, as you can tell, we're really just getting smarter on on the space, and we we know for certain client scenarios that we have encountered that the data we need is not sitting in servers and and so it's really intriguing to us, but this, but the you know The space has really struggled, kind of to your point, for a lot of reasons. And so, yeah, that's why we're trying to figure out what, what can we put? What can we pull together\n\nSoren Frederiksen  1:06:33  \nto build some simpler tasks? There's two parts of it, right, that it's easy to build task mind to take and figure out where you are, right? You can, you can with agents. In a week or two, you can build something that tracks what you're doing on your computer that now you're in Word, now you're in Excel, and now you're in a browser, right? And figure out what the browser is, the harder part becomes understanding the screen, right? Yeah, on this screen, you now know that here it says 13, and 13 means the average cycle time, because now you need to start doing OCR. The LLM 's will make that easier. We have not done that part of it, but you almost need to. And then I don't think it's a hugely like so if you're still hiring forward and doing it, it's not impossible for a few people in a group to do that. It's not a but it is a bigger task than where we just know which application you are in, because you can build that in a few weeks, right? That that's a lot easier, yeah,\n\nBill Karpovich  1:07:31  \nand how in the on the it's I was intrigued. You guys been out for five years, but you mentioned that you're down, that you guys are a couple people and clog code, right? That's kind of the the model right now. It's just just amazing. What's happening as far as software goes. Okay, well, listen, this has been great and and thanks for going over a little bit. I gotta jump here myself, and so let me compare notes with Dan and and we'll, we'll digest and circle back to you. But certainly really, really intriguing. Love, love the architecture, just the structure you've taken and the smartness around using notebook, Jupiter note notebooks and and, you know, a package thing. But this Python exit is exactly the architecture I've used in the past as a as a great mix. Everything you've articulated just seems common sensical and well thought out. So that's that's good. And so really, you know, I think like what we've heard from a product perspective. So let's let us digest, and we'll circle back around. I really, again, appreciate the time and being willing to jump back on a Monday that that quick. So all good.\n\nSoren Frederiksen  1:08:47  \nOne last thing, Bill, maybe if you want to just take that away, there's, let me just send you our docs section. Perfect. That's it. Technical Documentation. If you want to go check out some of that stuff, it's, I mean, you have the website, right? But this, we don't advertise this, but this is the documentation for all the stuff we do. So you can kind of go poke more if you feel like it.\n\nBill Karpovich  1:09:06  \nBut fantastic. Yeah, this is great. This is helpful. Docs are great way to get smart on things, and obviously AI generated, which is great.\n\nSoren Frederiksen  1:09:17  \nWell, there's an agent in there too. If you go ask that, you could go ask about our product, which\n\nBill Karpovich  1:09:23  \nis just the search, or is there\n\nSoren Frederiksen  1:09:24  \nanother one? Yeah, just on the homepage. On the homepage in the docs, there's a big girl sitting there, and if you click on that, it takes you to an agent which is kind of like a rag of all of our documentation. And it's pretty good at answering most questions of whether or not, do they have a calculator for this, and how would you use to\n\nBill Karpovich  1:09:46  \nthis stuff? You guys using get book for this, by the way, or is this another something else? No, it's chat\n\nSoren Frederiksen  1:09:51  \nbased, actually, for the agent itself. Okay, cool.\n\nBill Karpovich  1:09:55  \nHey, Soren. Great stuff again. Thank you. Really enjoyed it. We will absolutely be in touch and we'll talk soon.\n\nSoren Frederiksen  1:10:01  \nOkay, good, okay, thanks, Bill,\n\nBill Karpovich  1:10:03  \nall right, thank you. Bye.\n\nTranscribed by https://otter.ai",
  "takeaways": "",
  "url": "",
  "transcriptionText": "Bill Karpovich  0:01  \nHey, Soren, how you doing? Good,\n\nSoren Frederiksen  0:05  \ngood. We're still in the synaptic virtual office.\n\nBill Karpovich  0:11  \nI'm in a different, different one right now. Yeah, back, I guess. Yeah, we spoke on Friday, right? So, yeah, it was back back up in Maryland, where live normally was down at the North Carolina for the holiday, Thanksgiving. Yeah, thank you. Yeah. I appreciate it. Yeah. And Soren, as I mentioned, I that my colleague here Dan who wanted to join in and get acquainted and get a chance to talk a little bit following up on our conversation. So meet, meet Dan.\n\nSpeaker 1  0:47  \nDan, how you doing? I'm doing well. Soren, thanks for the time. Really appreciate it. Bill told me a little bit looking forward to learning about what you guys are up to and can offer.\n\nSoren Frederiksen  0:58  \nOh, is that a big computer in the background. Dan, or like, Oh,\n\nSpeaker 1  1:05  \nit is a like three in one, like CNC printer, laser engraver, and it is up and running because we're knocking out some personalized Christmas ornaments.\n\nSoren Frederiksen  1:24  \nOkay, so we do have a somewhat fellow nerd on the call here. It sounds\n\nBill Karpovich  1:29  \nlike, yeah, Dan's CTO, CPO. So okay, yeah.\n\nSoren Frederiksen  1:35  \nSo I used to be called the head nerd of mindzie. Took it off when we started talking to some bigger companies, but, yeah, it's, it's kind of how I see myself. But so I couple of things, I guess, with this, because it's, I normally don't do these, like you said, do like a customer presentation, right? I don't do those, right? I do the very technical presentation. So, so we'll carry it over a little bit, and I did a bit of an agenda, but, and I don't want to just go and sit here and go through PowerPoints, right? So it would much rather you just interrupt and ask questions. So I was thinking and like, maybe I can just show the agenda I kind of set up what I thought might be interesting for you, and then maybe, maybe maybe also just say if there's something else you want out of this, right? So, because I know, as far as I understood, you're trying to do it for, like, create, kind of your own platform, maybe OEM hours, or do something where you can use process mining, right? So yeah, these were some of the things I was thinking of talking on. And I won't even take this off of PowerPoint mode, because I'd rather jump into the product and show you that as well.\n\nBill Karpovich  2:46  \nYeah, so Well, I think these steps are, I mean, these topics are good, so it gets a sense of kind of how you guys think about this market. What I think is interesting and love for even if you and I, you know, get a little bit over some ground from from Friday to hear Dan, hear about it, and then obviously, this kind of your your kind of provocative view. Obviously, there's different different camps in this world, but this idea that task mining is is not needed or not essential, maybe. But you know that that kind of point of view around your your perspective and and then obviously we had this view on, you know, what is valuable within process mining, and we were a little bit like minded there, whereas it's not the fancy graphs, it's it's these other insights. But you know, you need to describe that in your words. I don't want to that also may get our quick conversation not hit it. So I love that point of view stuff. And then I think your view of the life cycle was going to map to your view of the platform, which I think is helpful. And then then I think we can dive in. So that makes sense to me. Okay, Dan, anything you want to prime Dan, or is it, let's dive in and it'll go where it actually goes.\n\nSoren Frederiksen  4:01  \nYeah, I mean, maybe that's just a little background on me. Came to Canada back in the 90s and actually worked on neural network. I was a new on the tooling side of a neural network company in 95 to a little after 2000 and did the tooling for neural network before neural networks kind of work. And then after that, we saw that wasn't really working. We were doing facial recognition. I switched into building software for 17 years for the casino industry. So if any of you ever go to Vegas and you get caught by the cameras there, like our face rack usually runs on a lot of these casinos, and we do instant reporting. So I did that for a long time on premise software, and five years ago, the partner I have now also James Henderson. He was coming out of a sale as well. I sold my company. He did as well, and didn't know what to do. And then learned about process mining about five years ago. So we've been in this space. We started the company about five years ago, and came to this from basically the perspective of James, run a company that had 1500 employees, and they would pay KPMG a lot of money to come in and look at the process, manually, interview people, and charge them a million bucks and give them report, saying you need to do these four things. They would fix those four things, and then nothing would really happen. Nobody would come back six months later and check if it actually worked, right? So he was the one that brought up and say, There's got to be a better way to do this. And we started looking into it. And process mining have been in Europe for almost 20 years, right? Created by Bill Van dalist, a Dutch researcher and professor, and he now is advising for salonis, which is the biggest company in the space. So we looked at that solonus was a little bit different beast when we started, and we started looking at different tooling. How do you do this? As soon as I saw process mining, I understood the theory. I thought, why the hell haven't we been doing this for all these years? Right? It's really funny. And if you look at this. It is so simple, because you take any data you have and turn it into three data points, which is a case ID for your support ticket, your P to P order or whatever, and then a an activity and a time, right? That's all we need to now do all of this stuff that we'd be showing so it's really funny, because it's very simple, all this stuff. So saw that happening, said, Let's go to we go consult. What do we do with this? And at the time, there were two companies that were just purchased, well, just after we started actually mine it. And the other one is path now, that was bought by solonas and Microsoft for like, 100 and 20 million at the time. So there was a huge amount of interest in this space. And we thought, I mean, I'm a product guy. I've always been so like, let's try to build our own because salon is so expensive and out of reach for most people. And it's, it's super good tool, but very, very technically difficult. And then there's, I don't know if you've tried any of the tool, the lowest end tool you can buy, which is super good, is called disco from a company, and they build a tool. The problem with their tool is, as soon as you could get up and running, and I learned process mining on it, but then it doesn't scale into industry. So you can't run it overnight, you can't automate it, you can't do other things. So it's a research tool you can use on your laptop to figure out your problems on your data, but then you can't send actions every day, right? Or start agents now or something else. So we wanted to build disco, but for enterprises, right? So we wanted to build a tool that was super easy to use. You don't have to be a nerd to use it, and you don't like we were trying to get a really low entry to people, and you don't need the price point of salon is also which they're like, a huge, huge price point. But we still want an enterprise. And I think I told Bill is, like, I've been doing software for 17 years on premise. I never wanted to do on premise anymore. So we did SaaS only starting out after two years. Half of our customers want it on premise, because we start selling to hospitals and banks. So we rewrote our architecture, and I'll show some of it. So now what we do actually is one of the things, we have three models we deploy in. So we have a cloud version that's multi tenant, and we actually deploy exactly the same model on premise for customers. So everything we do, and everything we do, and everything is showing today, you could take it and put it on premise, because the hospital we deal with, we're just installing a bank where their servers are not even allowed to be on the internet. They can't be online at all. So there we have to go on premise. And because we're a smaller company, we can't have multiple versions, so it's the same that runs across those. And then we have a desktop version, which is kind of disco, but just a little bit better, because there's a significant amount of money with researchers on their own laptops, that just runs on your laptop on there. So this is kind of how we see it. And our biggest differentiator now from our stuff, is on premise, because nobody really does it anymore. Apromoch had some which are off the game. IBM has a little bit of it, and they will do it, but they're IBM and like a massive company behind them, but none of the other vendors. Everybody is cloud, even salon is the biggest one. They don't support on premise anymore, and it's just become a big kind of business for us on doing it. So again, I'll just jump around a little bit, because I want to show you the product. I don't know. I find it easier when you see some of this stuff. And actually what it is we end up building. And so it is a what we build and what we use most, like, maybe half, maybe no, 60% are probably in cloud. So this is our cloud version that runs and you can access and we could set up a tenant for you. Can try this out if you want, but it's the idea of this is we do have the fancy graphs that you can do in process mining, where we take your data and turn it into these graphs, but it's not what we use the most. We don't typically use this. We use them for demos, and there are some insights you can glean from it. What you use is the technology that kind of behind that graph, right? Because you can do a lot of calculations on the graph. So if you see any of the vendors, most of us can do this, and you can zoom in on the graph and saying which steps happened before others. And then you can calculate how much time happened, right? And maybe to explain how we get here, right? Like, how do you get to this map, and how do you do any of this in process mining? And just stop me if you've heard all of this before, right? But if you have SAP, for instance, and you're doing P to P, because it's a simple process, purchase orders, there is one table that holds all your purchase orders, and that's either at line level or the purchase order level. That is now your case ID you have. So you go and grab that table, and then you tie that into saying, Bill entered a purchase order here, and then Dan approved it here, and then you received your goods here. And those are the activities, right? So you take a normal table as an SAP, you convert it into a format we can read in this tool, and then you upload it to the tool, and then nothing else happens for us to generate this, right? If you have those three fields, we can now just algorithmically generate this, and then you can See all the insights of how your process is flowing.\n\nBill Karpovich  11:40  \nThe key things in the Salesforce world that we've seen. The\n\nSoren Frederiksen  11:43  \nother thing you can do is you can see the variants. Right? Variants are, how many ways can you do my process? I mean, they think they do it. Always this way. Of these six steps. I always follow these six steps. But in reality, it's really like there's 1000s of ways typically a process is done,\n\nBill Karpovich  11:58  \nyeah, because how do you so, just just that, I'm just curious, you know, so we have seen very similar charts to this, right? So when you, when you look at this, this situation, and the what's, what's the technique you guys use to reduce this to signal, you know, because it's always like, Oh, really cool. It's not unlike the other things. But how do I, how do I reduce this to signal and and then how do I map it to some canonicalized view of of the process? Because even though there might be all these variants on the way, just based on the way the stages are set up, the reality is, there's, there's a superstructure this process that lives above this. And I'm just curious how you think about reducing to a higher level view of it that might, you know not live in the data, because the data was defined at a very stagey level. There's not this notion of kind of an aggregator. Yeah. Anyway, just just just curious. It's based on all of your expertise. Love to hear you, you know, kind of talk about that topic.\n\nSoren Frederiksen  13:04  \nSo basically, how do you make sense of this mess? Right? It's kind of, yeah.\n\nBill Karpovich  13:08  \nThat's a shorter, way more succinctly, yeah, yeah.\n\nSoren Frederiksen  13:11  \nAnd then the biggest thing you'll see in all demos, and it's really stupid. You like do this, right? And saying, Hey, look at how, look at how cool our software can show you this. And it has no meaning. There's no meaning. So What? What? What we do? And so there's two things, and one of those things you're asking about in process mining is called conformance, and it's where there are not you have a process and you think you're doing ABC, and then you can check how conforming are you to doing it in that way. And there are different ways. One of the ways is you can create BPMN, which we have, like, an editor for creating the process flow in BPMN, and then you can compare BPMN to the process and saying, wait a minute, you think you're doing this. Here's where you deviate. We haven't done that. And on purpose, we haven't done that because most companies are not even good enough to draw BPMN. You need a team, typically for that, and you don't have it. So what we've actually done, and now it jumps into something else, but we have something called log enrichment. So after we generate, as you probably show the chart, but after we generate your log, we can now enrich your log with different calculations, right? So we take your data that's coming in, and we kind of make custom attributes for this. And one of the enrichment is we have is for this conformance bill. So what we have found a lot easier and with these seven questions that are basically asking you as a business owner, and we would probably step through some of your variants, we would take some of the variants out, and we would ask you, it looks like here you are paying before you're approving. That's probably not good, right? So we sit down with you and try to generate rules for things you really don't want to happen. We can. We can bring some of them to the forefront and saying, wait a minute, in normal p to p, you shouldn't be paying before you receive your goods, right? You should receive your goods first. So all we would do a go in and set up rules here, where you're saying things should happen in a certain order, for instance. So if, if this, this admission, came before this other one, we could create a rule that does that. So we've actually found that this is a, we call it negative conformance, where we basically going to say there are things you know that shouldn't happen that are worse than others. So we set up these rules, and they will then trickle through. And I don't think I have a demo of it, but they will actually show up on your process map. So if there are activities you don't want to happen, we can color these things, for instance, but we can also calculate based on them later and and I think that's how we do most like, that's a very general view, but most of the times we will do things like this. There's lots of templates, and I can show you that will bring some of the problems to the forefront, and then that's other things we can do. So I guess that's the problem with like, getting to all of this. Does that make some sense? And how we make sense of this, that would be one of them.\n\nBill Karpovich  16:07  \nYeah, the enrichment concept makes a lot of sense. And like that idea of hunting, hunting backwards with rules. And say, if these rules were in place, what would have happened, or what's the Yeah, that's a that makes sense.\n\nSoren Frederiksen  16:24  \nAnd you can see here, right? So in this data, for this, all this, we can only show dummy data, right? Because we can't show clients data. But so there's only 106 different variants here that's showing in the bottom. And you can see the top one. In this case, happens 2020, times, and then all of a sudden, it's very few, right? So you only really need to go through the stuff that happens a lot the bottom one. So there's a lot of frequency filtering and all of the stuff we do and saying, if something you do once every two years, we don't really care, unless there's a real compliance issue, right? Like you do something that's illegal, so you very much filter it on that, because it's hard to and the other thing you do is you figure out, of all these steps we're showing here, which ones do you really care about? Because a lot of people will do so when you when jumping a little bit. But if you do a project, when you extract this out, right, you can find 10 activities or 200 activities, depending on how much we do. Typically, we say, start smaller. So we had customers that start really small, three or four activities, and then they find out there's a big gap between B and C. And this is the talk of whether or not you do task mining. Can we find more steps? Right? Can we find the steps that are in there? But we say, don't start with 42 activities, because it becomes a mess that you don't need, and half of those activities you are not in control over, you can't do anything about. So why even show them? Right? We're very much when. So what we end up with here that I showed is a dashboard. Nothing should go on this dashboard if you don't take action on it, right? So when you show a customer dashboard of any kind with their process improvements, then it should show some numbers on it. But maybe I should try to get back to a little bit. I think I lost a little bit of where we were. But let me try to get back a little bit and show you. Because if you look at the if you look at the project life cycle, right? If you look at some of this, there's a couple of things to it. The first thing, and I forgot to show it here, the biggest thing is really the buy in from the company, right? Why should we be doing this at all? We've done way too many proof of concepts for somebody who was just kind of interested, and we found the things for them they wanted, but then they didn't know what to do with it. So the process projects should always start with it could be an investigation and see where we have problems. But my shipment is too slow, right? I want to make that better. We have too many returns. Why is that happening? And why are the returns taking so long? So it's usually, it should always be a business problem. It's the biggest thing that should happen up front. Then there are kind of three phases in it. There's a data acquisition where you're going to go to the ERP system, pull out the data, then you analyze it, which is really our tool, right? We will do the analysis. And then afterwards, you say, Hey, you had this problem in shipping. It's all about your approval process too slow. Somebody has to now go in and consult and actually make the improvement in the company, right? What do you now need to do to improve it? We do these two stages, mainly, right? We don't do anything about fixing it, like consultants we work with will do this, yeah. And, and\n\nBill Karpovich  19:36  \nthat's, that's our core business model today, right? And, Soren, you mentioned a couple of the pain points that the customers might come to you with. To what degree are they asking today? Hey, how can I use AI to reduce by, you know, process, cost and XYZ area, by, you know, consent and am I, you know, with every CEO asking about, you know, where they're going, even the benchmarking, like, okay, like, if I have a sense of where to look, this is great, but how do I know if I even need to look?\n\nSoren Frederiksen  20:15  \nThat's the you asked about AI, because I know you guys do AI, right? But that's the so and again, maybe jumping ahead, but I still think it's better. So if you look at our product, we've had aI integrated for a long time into our stuff, and the way we do this also, because there's lots of different ways you can do AI. You can take a data set, uploads, chat, GBT, and you can ask it some of the questions you could ask our tool, but it has to write Python first to reduce the data, because often our data will be 10 million activities, and you just can't put that in, like not even Gemini. So what we do with some of that bill is, and there's lots more you can do with AI in this there's, there's a few things you can do it. You can help the analyst ask questions about their data, and that's one thing we do fairly well.\n\nBill Karpovich  21:02  \nShow an example while you're on the Yeah.\n\nSoren Frederiksen  21:04  \nSo, what can I improve in my process? So, and the way we do this, because also this depends on the model up here, and I'll show you we do this with this is currently done with open AI, but it goes through our servers because a lot of customers show up and they don't have anything. So this would just list a bunch of things, but it turns it takes the data that we've already analyzed, right? So we upload their data, we run templates against the data, where we know they want to ask about bottlenecks, like the standard things you can do with process mining, and we actually feed that into open AI like we kind of pre feed it in. We call it base knowledge, and now they can ask questions about it, right? So, and we do this in two ways. We either do it like this, but we also allow you to schedule this overnight. I want Monday morning to send this report to bill in an email, but only focus on what happened last week. So that's something we've done, and it was something we'd hope take off more. There's some problems with llms. Some people don't trust them. There's lots of problems with people are not allowed to be in the cloud. So because you are AI, we, what we actually do is we integrate. I have to jump into another one. We integrate with on premise, llms and pretty much all the vendors. So we can, we can set up the large language model people want to use in our stuff. So if I go into the settings of kind of my tenant, I've set up open AI LM studio, which is a local open router, and then I can use different models asking the questions, because the models are fairly different. So the biggest thing we do right now, and the main thing we do here, is integration to ask questions about your data. That's the big thing we are working on, which is a huge benefit, because if you get a new custom data from a client, and you are a PWC or entity that we work with, often, they don't some of them are very experienced, and they know how to deal with that right P to P they know how to deal with a new one. They don't large language models are very good at laying out the scope. How should I do these analysis what are the five dashboards I should be showing in a P to P demo for a hospital demo? What should I be doing? So there's also the analysis side. I don't know if that answers your\n\nBill Karpovich  23:33  \nquestion, yeah. So you guys, you said you guys been working on with aI mean, guess today's the three year anniversary of chat GPT, or somewhere, maybe not today, somebody somewhere close. How long ago did you guys get it into your product?\n\nSoren Frederiksen  23:49  \nAnd go ahead, almost six months after chat GPT came out, we put the first version in. And the bigger problem in the beginning was that you couldn't feed it a lot of base knowledge right? The context window wasn't very long. Now they've gotten so much better. So in the beginning, it was much simpler questions you can ask it depending on the model you have now, and that's why you can switch our model up here. And you can say, I want different models, because it really depends on some combat so much quicker. So, but where we actually see that better benefit is actually well for the analyst, this is helpful, because I can get an overview, and I upload my event log, and for the first thing, the way we did it before large language models, where we have a bunch of templates, so you add your data in, and then we have all these templates that answer standard questions for you, and you can add these, and they will just automatically throw in different things that you could do, different mainstream behavior you could see, yeah, right. But now the good thing about since we have these templates, we can take all of those, and I need to go back and show you, but all of ours is built with notebooks. So we built up this string of notebooks that have little blocks on them. We built up and all of them can convert the visual prettiness into something an LLM can read. So all of them can kind of speak LLM. We can output JSON or some other format to the large language models. So they can read over this for you instead and say, Hey, Bill, this is your problem with your your process, which is, and we do that in two ways. We do it in the product, but we also allow you, we have actions where you can do this outbound. So this is probably what would be interesting to you guys. We can take any of these calculations, send them out, and let you write Python that can then do whatever you want. So you can, you can kind of lose our product without maybe even needing this, right? But it just it used us as an engine to feed into it. And maybe, maybe you get back there on showing, if you look at how we build our things, our architecture, a little bit, and if you look at how you do projects, and this was the big problem with like socelona 's. Can do this stuff, all the big vendors can, can be part of a pipeline, right? How do you become part of an organization? Because running process mining for analysts are not very interesting. It has to become part of the organization 's day to day life, right? We want to send you emails. We want to integrate with other systems. Otherwise you are a data analyst, nerd tool that sits in the corner, right?\n\nBill Karpovich  26:26  \nAnd how does that mean? Trans becoming a diagnostic tool? This is, you know, one of the big questions we've been wrestling with, right is, you know, one time, diagnosis is interesting, but you know, you tough to make money and tough to build a business that way, and you're never going to get the benefit to the client, because it's going to be a journey, not a not an event and and so obviously, having this reporting and having action hooks and is all about kind of getting to the operational, ongoing, continuous improvement part of the life cycle, how successful as the industry been getting there? And how about for you guys?\n\nSoren Frederiksen  27:08  \nNot good enough. If you look at most of also, if you look at Salon 'storm track, which are, like the biggest part of our industry, right? They don't almost say process mining anymore. Either. We won't go out as a process mining company. We'll say process intelligence more than anything, but most of what salon is does is not operationalized. They would like it to be, but it's not. It just hasn't gotten there. And I think it's because they didn't. They came out of academia, so they did all these projects, right? And if you were to look at a typical project, people still like to do POCs. We hate them, and we try to stay away from them, but we have to do some of them. So if you do a like a proof of concept, it's a one time deal, and you figure out, yeah, your process is slow doing these things. We try for all of ours to get in and integrated. And I know you do hospitals as well, right? So maybe I can show it with an example. Bill, I think I have so if you look at a hospital, for instance, I think, is this my Yeah, inpatient discharge, right? You can, you can write dashboards. So you could do a command center dashboard that tells you things, how many are admitted, and just numbers from your system, right? And you can do this historically to find the problems right. And then what we actually have, and we have this running in a command center, and actually in Riyadh Hospital in Saudi Arabia, where they run this view in their command center. And this is what we'd really like to get to, where you basically break down your admission into stages. And then you look at because we have all the timestamps of all of this stuff, right, we can now say,\n\nBill Karpovich  28:48  \nlet me make sure I just understand this. So it sounds like the approach in here is, yeah, you have operational systems, but typically their dashboarding and their ability to create context just is not great, right? And then step one almost, is just having a better dashboard. And it's a dashboard that has time sensitivity as as trending has, you know, whatever the enrichment is that you guys have caused this to happen, and you're creating a visualization that can be updated close enough to real time, and is operationally valuable enough that you become part of their operational desktop, or at least the management 's desktop. Is that the right understanding of the chain of connection?\n\nSoren Frederiksen  29:30  \nYeah, that's what, that's what we would like to be in most of these scenarios. Because if you do these proof of concepts, there's like a year between you do a proof of concept or something, but it it takes you a while to actually get between new like new new projects. And if nothing happens in the business, if they don't take action on and it can happen, right? They do analysis once, and they go offline, they go fix something to process, and they go back six months later, and they do the same analysis, right? Which manual we have a huge, actually, a insurance company, and they do life claims. And one of the big problems they have had, they have these Nigel forms. They call them, not in good standing on death certificate, death orders, and they just didn't know how long their claims took. They didn't really have any numbers on it. So they're trying to figure out if a client submits a death certificate, like a death claim, but their form is not in good order, they have to send it back to them. And that was the process. They didn't really and it adds a lot of complexity in their business when, when it takes too long to pay out a death, death claim. So they're actually, they're currently still just doing it manually bill so they will, because they have a lot of problems integrating our stuff with their on premise for security reasons, right? They they're not allowed to. So they're, they're uploading every, every month they upload a data set, and she manually updates all their charts and graphs and gives to people. But, and we've just, we're just talking with them, for instance. So we have also, we have apps in everything we do. So you can, you can set up dashboards, but we also have apps you can run and so you can take, we have the platform for the analysis. They work out all of this stuff, and they set it up, and they click things manually. But then afterwards, you can create your own app where you say these dashboards are now important for this role. So you're actually allowed to go in and say, Dan needs this view, Bill needs this view, and we just give you a login, and it's basically, it's setting up a bunch of favorites for people, but now you can see only some of these things, but it still means you you log in and check this out, and this is, for instance, what runs in a command center. The command center wants to know what's happening right now and also want to see what happened during the day. For instance, they would set those up. I\n\nBill Karpovich  31:56  \ndon't know. So I don't\n\nSoren Frederiksen  31:59  \nknow if you want to know how we do some of this, or if you have other questions on\n\nSpeaker 1  32:04  \nsorry that those would be my question is, like, if, if we had, like, a mutual customer, stick with healthcare, if that's most comfortable, what what needs to happen On the customer 's side to start this process?\n\nSoren Frederiksen  32:22  \nSo if you look at and then, so the biggest problem is always the data, right? So if you look at here, like a whole bunch of different ways, you can commission and get the data out. We have two kind of main projects. The one I've been showing so far as we call minds of studio that does all the analysis of all the data, but 60 to 80% of most projects is actually getting the data right. How do you get the data from their source system into the and how do you transform it right there? So there's two steps in that. It's getting access to it. First of all, for you, do they trust you? And then the second part is actually converting it from those tables into something process mining can read. And our data designer does this. It runs a bunch of SQL queries. It uses AI to write the SQL queries. And then, if you're like, if everything is on premise, which this one's showing, it means they have an SAP database. We put the data designer in, and we push the data into minds to studio fairly easily. And then we just schedule this, typically, to run daily. For a command center, they might run every three minutes, a smaller subset of it. And so this is what we want to get to, that it runs every day. What we often start with is they don't trust you. You're new to the client, so they don't want to give you data access. So they show up with CSV files, and we just upload the CSV files, which are from the database, and still use our data signer to convert that into data. So this is, to be honest, the biggest kind of hurdle in doing process mining for a client, you have this upfront. They're not going to really pay for it, because they don't really know what's happening, almost, and you don't see this. But you have this data transformation you have to do upfront. That's kind of the biggest cost of process mining, is I gotta do this. And if I do it to SAP, and I've done five saps before for P to P, it's easy, right? But if you throw me in a totally new process, I don't know what. I don't know the schema of the database. Now I gotta figure this out. And databases are never documented. They're you're on your own, and our data designer actually will do this, and we have a co pilot for data science, so you have to write, you write a query for every activity you have. So every, every time, if you look at this more time, if you go into the database and there's a timestamp in the database that is usually somebody doing something right? Dan updated the record at this time. He closed it. You received the good at this time. So you write a query for each and then you transform it. So if you do a proof of concept, you could do it with CSV files. We try to normally get access to the database, yeah, and then we do the transformation, push it in, and now you have the data you can analyze. And typically, then it starts with a historical view, so you go back to them and saying, and this is where it's really good. We have a lot of consultants now that use this to show how bad their process is. To really get to after work. If you're going to look at anybody 's process, I don't care who it is, you can always find flaws, right then? How big are they? So they use this very much to go in and they open up and say, You know what? You have all this rework you're doing, like you keep doing the same activity over and over as a common thing. Or the duration between these two steps are so long. Why is that? Right? That's the and\n\nSpeaker 1  35:37  \nwhat, what's, what's a common observation or mining period before insights tend to arise. Yeah, so\n\nSoren Frederiksen  35:49  \nwe, I mean, I can talk to one we just did in Germany, for instance, we did one for a large train company. They they lease out trains, and they just understand the size. They repair about 68,000 wheel wells a year, right? So they own the trains, and they lease out the trains to the government and other people on the train tracks. So their big problem was that, how do we not have the trains in the shop? Right? As long as they're in the shop, we make no money off of them. And so we were looking at their procurement process for all of that stuff. It's so in that process, it was a purchase, like a proof of concept, and it was run by taxa consulting, right? TCS consulting ran the project. The problem they had is they hadn't gotten they hadn't asked enough to get data access. So we spent a lot of time just getting access to tables. They had four customizations in their data that we had to understand first. We couldn't get the experts. So it really depends on how much access you have. So I think we spend about four weeks getting the data from theirs to our system, just getting the data and then analyzing it was less than a week, okay? And the outcome we then had, because it was very like, once you format it. I mean, the way we set up all of our stuff is clicking and like, it's no no coding, right? And we try to use templates and processes are very much the same, like different nuances. And what we found there was, like, we showed them that these three steps cost them 30% on their wagons, which, like my partner then calculated into this cost you $2 million basically a month to have these train direct because of these two processes. So do something about these three steps. And then the consulting company came in and said, these are the things you could do about it, right? But so it was really one dashboard with like four numbers. There was the outcome of all this, but it was kind of the savings for all of the stuff on the outcome. So but, and we did that, but we did that with CSV files, which is a huge problem also, because the people exporting the CSV files didn't know how to do this properly. So if you don't do it correctly, you can't import them again. So if you don't, for instance, if you put a comma in a CSV file, and you don't, technically do that right, the whole thing breaks and you lose records. So we spend a lot of time on that process. So the better you have control over getting to this data, the easier it'd be. It becomes okay?\n\nSpeaker 1  38:18  \nAnd if, if there is a process that spans, let's just say, like SAP and Salesforce, for example. Does the data designer needs to be connected to both of those, or is there some way that you guys have figured out? Yeah, if part of the process leaves a system that we're monitoring. No big deal. Here's how we can still gather insights as a result.\n\nSoren Frederiksen  38:46  \nYeah, so there's two different ways you can do it. Depends on if it's two different processes that don't overlap. You can do it as two. So I don't know, does my architecture show this? I think it might show on here. Yeah, it does, actually kind of so when we put stuff in, you put it into data sets, right? So once you converted it into an event log or a data set, that's now one set of data that could come from one source, and it can also technically come from multiple sources, one data set, but if you have one data set, so what you can do is you can add two data sets. You can enrich both of them you can create these investigations, which we do, which separates more logical things? I want to talk about Europe here, or us here, or this is for my daily process. This is for my historical and then underneath these, we have these analysis. And then the analysis can then get thrown up on a dashboard, but you can take two source data set and put on one dashboard. So one way you could do it is you could actually extract it separately and then join it back up on one dashboard. But it's two different processes you're just showing in one place, right? You could do that. The other way you can do it. And I think I can open our data sign. I should be able to let me just log in. I can also, if I log in again, you can kind of see I have access to quite a few tenants. So this is our tenant bill. I know you asked for it, so we have multiple tenants on but if you go in and look at our data designer, I think I have demos in here, yeah. So this was actually the company we worked with. But can I show? Got more data? So this is what the data design and look like. You have a case attribute query that that finds all the case IDs, and then you have a query for each activity. And these are very small. So the SQL is not very difficult here. It's really just and then it compiles all this and puts it together for you if you want to connect to different data sources, right? So you can, you can connect to a DataSource, and you can have multiple data sources in one extraction. So you could connect to two different ones, these are kind of the ones we connect to now. So you could technically select multiple these sources, and we can pretty much do anything that has a database behind it, right? Because we can write queries against everything. So if you give us an ODBC database from SAP, we write SAP SQL. If you give us a database from, yeah, from So Microsoft is common one, right? We write what's called T SQL, and you can have multiple of these and write different queries, and we just join these together and turn it into an event log. So what this means, Dan, is you means you have to have a SQL database. We currently do not connect to REST services. If you look at somebody like salon, and Salon has forced you to put all your data in their data warehouse, and then you extract from there, right? So they own the data warehouse, which makes them things simpler for them. We don't like to. We're not data warehouse people, right? That's not our job. So if you have something in Salesforce, for instance, they don't have a query language, right? As far as I know, you can't really query it. You can't go directly to the database. So there's a rest. So you'd probably have to move some of that data into a queryable location to use our tool or write something else to pull it out. But you could take multiple of these datasources and combine them into one dataset. So you could put four activities from this and then four activities from Salesforce, and then four from somebody else. If you want it to okay. It doesn't. It doesn't happen that much, though. It really doesn't. And I think that, because the biggest thing we talk to people about when we do this, find three to six activities. First, pull it in, and the data sign is very easy to run it multiple times. Find these three, write this three simple queries, pull it in and look at your data, and then you find out, you know what to answer any questions we're missing between these two steps. And now you go on, you find things in those steps we've seen, especially work. We work some Indian consulting companies that went out and they got 42 activities, right? And now you're sitting there with a pile of mess that you can't really figure anything out, because half of the activities you got were not critical, right? When somebody updated a record is typically not important unless you know why they did it. For what reason did I go off track again?\n\nBill Karpovich  43:13  \nSoren just back to the point on the data extraction while we just to drain it. So you know, certainly the task mining piece is a compliance rat's nest, right, in terms of getting on people's desktops and and getting them convinced on all the different ways that it's safe, even if it's they can get through the social parts of it, on the data side of it. I mean, it's gonna be on the process mining side of it. And you showed your spectrum of support, which I think is wise, right? So everything from, you know, kind of sitting inside their firewall with the letter, yeah, we're sitting outside the firewall with SAS, or say, and, you know, so there's a bunch of different compliance realms that get triggered, right? So if it's Hey, I'm taking it off, off of my network, that's going to be the network security consideration. They're all kind of, you know, obviously work together, but different enterprises will have different sensitivity. So in the case of hey, if loans doesn't leave my my my network, fine, as long as you can do it inside of my DMZ or inside of my firewall with your local version. You know that? Can you know, if I think about all the different traps that can be set compliance wise, and how to get through that gauntlet most readily, just curious what your experience tells you right then, of course, there's the CSV data. Hey, fine. You don't have to have system access. And if you do your analysis inside of my firewall, great. But if you do it outside of my firewall, not great, just in the real world, given your experience, how does that unfold? And do you need a Swiss Army? Because you never know, and you're going to need as many options as you can. Or is there a particular pattern? It's become clear.\n\nSoren Frederiksen  44:53  \nYeah, this shows pretty much all the ones we do, and once we find is needed. So the one we like, the best bill, is the one here, and that's basically everything run on our SaaS servers. And to go into their database, they open a port here to go into whatever database it is, Oracle or whatever, and then they whitelist our servers, right? And that means we can access it. We get in, they set up a read only user where we have access to only\n\nBill Karpovich  45:18  \nthis obvious, obviously for you, it's the best, yeah, but\n\nSoren Frederiksen  45:22  \nno, but let me explain the sort of the problem with that is, security wise, is not really a problem because it is locked down tightly, but it's hard to convince a lot of IT companies to do that, sure, right? It's very difficult, don't\n\nBill Karpovich  45:33  \nthey also do then sock two audits on you everything, and data retention strategies and like, what? So what comes with that?\n\nSoren Frederiksen  45:38  \nYeah, we are SOC two certified. We have to be. We can't be without it. The problem with that is they now have to be good at narrowing down your user access into their database, right? Yeah, sure, yeah. So there's lots of so that is what we try to get. Half of the times we don't get this right, or more. Then the other thing you can do is, if you go everything on premise, that means now they're maintaining all the software, and that's what we do for banks and we do for hospitals. The problem with this is you as the consultant, or if you were that, lose control, because you have harder time getting through their analysis, and you have harder time getting to their\n\nBill Karpovich  46:17  \ndoes this look like get me a VM or get me something in your container farm? Is that what it\n\nSoren Frederiksen  46:22  \nlooks like we run off of Windows VMs. A bunch of reasons for the historical but, yeah, if you have a virtual machine with 16 to 32 gigs of RAM, we can run on it for like a modern Windows machine. And we don't, we use SQL server as well, which we can install on the machine. Or you can use a enterprise SQL Server. So installation is actually pretty simple, and now we also we completely support that. You don't have to be online for updates. You can do everything in a completely closed box. What happens a lot and where you like exactly what you asked. This difference. So if we put the data designer, which is the piece that does the extraction right process mining rarely needs personal data, right? The most personal we ever get is your name, and we just as well can get your custom like your employee ID. So if we do this scenario, it does mean that data design becomes more difficult, because I now need a VPN into your servers, or I need to be on site, right? Because very rarely we can give them. We have packages for SAP that we could give you, but there's almost never two that are exactly the same, right? Unless you find an industry that has the same provider and it in Salesforce, and you'd always do the same. You could, you could do this, but there's always customization. So doing this, you now need to be on premise. We have a guy that's doing this right now for a hospital in Ecuador, and he's actually taking a laptop on premise with this, doing all the work for the proof of concept on their premises. But now it's okay to push up to us in the cloud, because you're taking very little data, and they can see what data is getting pushed up there. So we, we find much less resistant with this. If they're open to cloud at all, right? If they're not open to cloud, it doesn't matter, then they have to do this option up here. So this, we found Bill a lot easier to get through security, because they can see what we're pushing and we're not opening inbound ports for their stuff. If you're if you're if you're going into Salesforce, though, it's almost the same where this is all just in the cloud, right? Yeah, because, yeah, so and we do, we don't have a connector for Salesforce, because it's an API, but we do have one for snowflake, for instance, which is also a cloud provider. So\n\nBill Karpovich  48:41  \nhow long does in the real world, the customer says, hey, I'm interested in this. How long does it typically take to get through the compliance process? Whatever the security pieces are, what's your experience?\n\nSoren Frederiksen  48:55  \nSay it's so it's been all over the map. Our insurance company, which is really regulated, they took two weeks. But that's because they bought in very small no data connection, no data access. They create their own event logs and upload them, so there was very little commission. But we had Motorola, it took us, what, 12 months, I think, to go through their security.\n\nBill Karpovich  49:17  \nThe PII argument is pretty good one, right? I mean, there's no, I mean, there's really no reason why you need PII.\n\nSoren Frederiksen  49:24  \nNo, there, there isn't. There isn't. There's very little. I mean, it is really nice to have names because,\n\nBill Karpovich  49:30  \nlike, account data, like, normally, if you're, like, your your P to P, example, it would be interesting to know that. Oh, but, you know, accounts in and in the US for the ones that are causing you the problem. So you got to know, like some industry data may be, hey, and by the way, it's GM who's causing your problems. Is that considered PII at that level? And is that relevant? Or is it typically happen at our level?\n\nSoren Frederiksen  49:55  \nNo, but it is sensitive. So in purchase, like we do a lot of financial because they're in process mining, they're not, they're not the most interesting. And we're trying to do a lot of others that are more interesting, but in that cases. So if you do AP or PDP, you need vendor, and you need, you need numbers, right? So if we go in and we get some of the client to do this, we know how much they sold last year, right? Like, if we have so by the way, also, we work in two different models, either they allow us into their to their tenant, because they want help from us, right? And then we can see the data, or we can be cut out, and then we run we have no idea what they're doing on our servers, but there so that is sensitive. But it's not PII, right, but it's, it's sensitive data to obviously know how much total sales they have, or how many invoices they have, but it's not PII what we do a lot Bill. And so because we are socks who certified, we don't have any. And that's the other problem. If we recommended or sold a data warehouse, we would trigger a secondary vendor in our that. So the sock becomes a lot more complicated for that. So being a being one vendor is easier, being a smaller vendor is harder, because we're not as big. So for us, it's much better to come in with consulting houses, because now they trust, they trust TCS, and TCS have said they trusted us, so they like it makes it easier, and then we just provide then, in that case, we just provide them our documentation for being SOC and PCs guarantees it or NTT, and then it makes it easier for us, but it is always a getting to the data is the biggest hurdle. And I'd like, I haven't even shown you much doing the analysis is comparatively fairly trivial. So if you're thinking of doing all of stuff, think about, where are you good at it? Where can you get the data? Where do you know the data? Where do they trust you with the data? Because if you solve that, you're a lot further ahead. So maybe I should just show it. If you want to do analysis right, we build up the way we build up the analysis. Are these blocks we put on the screen. So this is built after something called Jupyter notebook, which is basically you have data coming into the top of a notebook, and then you put different blocks on there, and you manipulate the data. And so we have two blocks. We have filter blocks, and all they do is this one, for instance, remove the cases where the activity name is patient departure. So you can do filtering. And you do filtering by just clicking here add. And then you select one of our filters. Seven of our filters account for about 80% of all the things you want to do. So cases like this filter would filter find me all the vendors called Coca Cola, right? Or find me all the vendors in North America. So you add these blocks on our notebooks, and then the filtering, and then you add visualizations, which we have 73 of where you can do counts or grids or breakdowns or the charts that you see. So as you're doing analysis, you're basically building these up and where we make it just easier. We have pre built all of these final ones. So if you add any of these, we just built the blocks for you. So, so when you get the analysis, it's fairly easy to the biggest problem with the analysis part is, what the hell am I looking for? Right? What? That's a big problem. I get all this data, where do I start? And that's AI is really good at kind of helping with that. It can see, we'll give AI all of the data in the breakdowns. That's normal for process mining, and can guide you along the way to say, Yeah, you should probably be looking at the rework, right? So we have a for instance, in here. If you want to look at rework, we have a rework template. Let's see how it does on this data. So if you add this template on to your data, it will show you likelihood of repetition. So this doesn't cases with activity repetition, but it will show you which ones are repeated the most. And so medical administration adds 17 days whenever you repeat it. And it's, this is how many repetitions they did in this data set, for instance. So we have all these templates you can add, and then the AI can also look at this and kind of help you along the way. So, so, so building the analysis itself is not difficult. Knowing what to look for is kind of the more not, I wouldn't call art, but that's where it takes a little bit experience, right? What could I find\n\nBill Karpovich  54:23  \nif you, if you click the help button on your AI button over there, what is, what is that doing? Just curious.\n\nSoren Frederiksen  54:29  \nWhat? Oh, this one, yeah, something we actually just playing with. It just tells you what you could what you could ask.\n\nBill Karpovich  54:33  \nLet me see if I can make this bigger. Okay, so that's more\n\nSoren Frederiksen  54:36  \nthe help. Yeah, this is a hard coded thing that just comes up and yeah, just some common questions you can ask, yeah, yeah, okay.\n\nBill Karpovich  54:47  \nSo see where okay, but it doesn't sound this seems like okay, got it.\n\nSoren Frederiksen  54:54  \nSo I think what's what I what we found, is interesting. And if you look at the structure a little bit on it, I'll go back to the chart. So you can put data in manually. You can put it in through our like we have an API, so you could also write your own code, take it from where you want, and send it to our API and create datasets and update datasets. So there's a few people that do that as well. So and we have APIs that you can access by tenant and so forth as well for our enrichments. And so what we did when we designed this is we wanted to be no code, we wanted to lower the entry, and then we kept adding more blocks for people asked for more things, right? And then finally, like, we can't add a block for what everybody wants. That's the problem with no code, right? You run into things you can't do. So what we did is we actually integrated Python in a couple of places. We said we'll do 95% of what everybody wants. If you want to do anything else, you write Python to do exactly what you want. And we do the same on the outline bill. And this might be where things are interesting, because we can actually take any of the analysis we do and then send them out. One of the things we do the most where you don't have to code is every Monday morning, I will do an analysis, and I'll add a filter to my analysis on whatever the filtering is. I had to filter here somewhere. So I'm filtering anything that doesn't have departure this grid down here. I want that email to myself every Monday morning, and that could be my slow vendor invoices, it could be anything where people have done like paid before approval. So we do that, and that's without code. You go into this action module, and you pick the data you want, and then you take different steps. And the steps you can do is send an email out, for instance, and then you schedule this to go out, and the actions we have email is the most used because it's the simplest, right? It's very easy to email for but here is where you can take any of the data you select and actually write some Python to now do whatever you want you can do in Python. So we will run the Python on our server for you, but it could go and interact with whatever the server can reach right? So if you have, I want to push this to Power BI, I want to do whatever we give you all the data behind our analysis, and then you can go write this Python. So that's kind of how we've made sure that we can be part of a pipeline, that we're just not a like our own box on there. But see, we have all kind of come up in time and arena time. I don't know if did we cover most of it? Do you guys have\n\nBill Karpovich  57:30  \ncovered a lot? But we that I'm, I know personally, I could go, like to keep going, but maybe, maybe, if you're up for it, we can schedule another time you had the OEM opportunity here, what was on your mind there, that you wanted to share was really intrigued by the model, by the idea that us isn't important to you. Just speak to some of that and how you guys would think\n\nSoren Frederiksen  57:57  \nwe don't have one customer in the US. I mean, we're not really going after customers. We work with a lot of consulting companies, so TCS, but it's out of India, so the most of the consulting companies are actually off US soil. So we do have, and I think this has even been changed a little bit. So for all of the server, if two things we can do, you can either keep it on our servers and use that. But you could also install your own server, and then we can set up and you can actually change the application settings. So you can remove all the company information, you can remove the logo. You can actually set up your colors, so we allow you to change all the colors background, so you can kind of skin this to make it look like your own. And I know we have a demo somewhere, I think for PwC, but yeah, so that's the idea of it. And then our name is kind of removed from all of it. And then you just brought this human product\n\nBill Karpovich  58:52  \nat the highest level. And you're, you want to stay on the technical side, but if I was just You just beginning to think about it like, what are the economics of something like this potentially look like? Like, how do you guys price it?\n\nSoren Frederiksen  59:05  \nI don't really know. In the OEM, we typically pill price one analyst for about 10,000 a year. And then there's packs of users that don't quote me on it, but we'd like we do a five pack of users, because you can, you can access this as the analyst that can set up all this stuff, and then you can be the user that uses this afterwards, right? So we charge, typically, for those things. We don't charge per process in SaaS, we still don't charge for, like, how much data you have, because we haven't had any that are so big. So we, we try to make the pricing easier.\n\nBill Karpovich  59:38  \nAnd I think an average customer then becomes how much per year, approximately.\n\nSoren Frederiksen  59:42  \nBut it really, really depends, like customers between 40 to 250 Yeah, all right, we try to and cut. I mean, if you go into salon and 's right, they almost don't pick up the phone, unless half a million dollars, because they're so big, and the amount of value we have to find in a process to go in and charge half a million dollars is, is like, it has to be a massive organization. We, our best spot bill for companies is probably half, like 100 100 million to about a couple of $4 billion of annual revenue. It's kind of where we, if it's a lot smaller than 100 million, we it's harder even to find any anything you can improve for them. So that's, that's kind of where we play. And if it gets much bigger than 4 billion, we start being it's not something we handle as well anymore. I mean, we don't handle 100 million records a day, right? I mean, there's, there's certain limits to what we can do. So and OEM. I think with all of this, if we don't really care same price for on premise and cloud, we don't really care the cost of running this in Cloud is not massive for us. So, so if you go on premise, we cost increases for support if you're in cloud. I mean, we need to run the hardware right. But yeah,\n\nBill Karpovich  1:01:00  \nI wanted Dan to hear your comments around task mining. Could you just just talk us, given your expertise and living in this space, love your your point of view there?\n\nSoren Frederiksen  1:01:09  \nYeah, yeah. No, I we have it. We've done it. And really what it is is you basically track how much I'm I'm spending in the Excel versus how much I'm spending in the in the product. If you really want to do it, well, you should tie it into the case ID that you're currently working on. And if you have to do that, you would have to screen, scrape all of the different screens and figure out you're now an SAP, and where is the purchase order number and stuff that gets really complicated. So we've actually simplified and said, you enter the case ID when we track you, we are not the company that will sit in the background and look at you for 's and then do all of this. We think it's too intrusive. So what we do right now is we take you, tell the case ID, you go do some work, and it all ties into that case ID. We know all the applications you jump around in, and we can say you spend this much time in Excel, you spend this much time here, and the case ID now becomes part of the event log. We then upload this, and now we have these extra steps, and we just find that it's almost as easy as because really, why they want to know is like, how much time do you spend in Excel? We find it is so much cheaper and easier. Just go ask some of the employees do a bit of survey. I'm just, yeah, I'm not a biggest fan of task mining. I think it's intrusive. I often we haven't seen enough where we actually needed it. Some wanted it, but they they could have done it by just saying, You know what? We have the problem between A and B. Let's figure out what we do in there, and do that manually. So what we do also is we do actually allow you to estimate cost on your activities. And we use that quite a lot where. So if you go in and look at it's in our enrichment stage, you can say, this activity we estimated to cost this much. And now you can then use that to calculate on and then you can add up all the activities you did for that, and then that gets you 80% of the way there. So we basically put it into this, oh, I clicked the wrong thing. We put it in there so it makes it easier, and then you can now use it as a calculation. And we find that so much easier than task mining. A lot of companies don't agree with me, because a lot of people sell task mining. I'm just not a big fan of it. I know. Did that have any questions on particularly or I wouldn't. I wouldn't\n\nSpeaker 1  1:03:33  \nappreciate the perspective. And now you guys feel that you know you can accomplish your customers goals predominantly through process mining. Less, less is better, right? If we can still create value with fewer tools,\n\nSoren Frederiksen  1:03:51  \nwe've, we haven't had it enough, that's the thing, right? We haven't had task money that where they really wanted it enough to and I wouldn't, I wouldn't say you should OEM our task mining. It's It wouldn't be good enough. If you want to do task mining, don't base it on our product. It's just not good enough, right? So that's the other thing. Bill to it. It's just not it's not really what we want to do. So if you really need task mine for whatever you're about to endeavor, you got to find it somewhere else. I'd say we, like I said, we did it more to be able to check the marketing box and the feature box that we have it, but we don't really know.\n\nBill Karpovich  1:04:24  \nWe don't look. Is there anyone that you do respect in that space? Who, if we were saying, Hey, you guys could be a partner on the process side, XYZ on the task side, is anyone?\n\nSoren Frederiksen  1:04:35  \nNo, we actually, we work with scan, but there's semi strange company. They're pretty good at it, scan. Ai, there was just a slightly strange company. I mean, Microsoft does it really well, right? But, but there is such a big ecosystem, and they're hard to find out their products. They do process mining as well, but, and they bought one of the companies. They bought mine it they were called, but it's, but it's such a the problem with the big vendors is, like Microsoft, is, I produce tons of Microsoft products. Process mining is like a side project for them. So we know from people from mine it, and the product is not getting the attention because it makes no money for them. So they got a pretty good product that's in there, but it's not, it's it. You have to use it with their power platform, for instance, and it's, it's complicated, right? It's, it can do a bunch of stuff, but it's a lot more complicated. And so then I, but I don't, yeah, I don't really know, Bill, I'm not the right person to ask. I think, because I don't, I don't like it as much. So, and it is it. I mean, it's a choice. We keep talking about it, and partner and I if we should or not. But so far, we stayed away, actually curious, because I know that's what Ross asked me, also coming into this, right? Have you had somebody who wanted to do it or,\n\nBill Karpovich  1:05:53  \nyeah, I think you know, as you can tell, we're really just getting smarter on on the space, and we we know for certain client scenarios that we have encountered that the data we need is not sitting in servers and and so it's really intriguing to us, but this, but the you know The space has really struggled, kind of to your point, for a lot of reasons. And so, yeah, that's why we're trying to figure out what, what can we put? What can we pull together\n\nSoren Frederiksen  1:06:33  \nto build some simpler tasks? There's two parts of it, right, that it's easy to build task mind to take and figure out where you are, right? You can, you can with agents. In a week or two, you can build something that tracks what you're doing on your computer that now you're in Word, now you're in Excel, and now you're in a browser, right? And figure out what the browser is, the harder part becomes understanding the screen, right? Yeah, on this screen, you now know that here it says 13, and 13 means the average cycle time, because now you need to start doing OCR. The LLM 's will make that easier. We have not done that part of it, but you almost need to. And then I don't think it's a hugely like so if you're still hiring forward and doing it, it's not impossible for a few people in a group to do that. It's not a but it is a bigger task than where we just know which application you are in, because you can build that in a few weeks, right? That that's a lot easier, yeah,\n\nBill Karpovich  1:07:31  \nand how in the on the it's I was intrigued. You guys been out for five years, but you mentioned that you're down, that you guys are a couple people and clog code, right? That's kind of the the model right now. It's just just amazing. What's happening as far as software goes. Okay, well, listen, this has been great and and thanks for going over a little bit. I gotta jump here myself, and so let me compare notes with Dan and and we'll, we'll digest and circle back to you. But certainly really, really intriguing. Love, love the architecture, just the structure you've taken and the smartness around using notebook, Jupiter note notebooks and and, you know, a package thing. But this Python exit is exactly the architecture I've used in the past as a as a great mix. Everything you've articulated just seems common sensical and well thought out. So that's that's good. And so really, you know, I think like what we've heard from a product perspective. So let's let us digest, and we'll circle back around. I really, again, appreciate the time and being willing to jump back on a Monday that that quick. So all good.\n\nSoren Frederiksen  1:08:47  \nOne last thing, Bill, maybe if you want to just take that away, there's, let me just send you our docs section. Perfect. That's it. Technical Documentation. If you want to go check out some of that stuff, it's, I mean, you have the website, right? But this, we don't advertise this, but this is the documentation for all the stuff we do. So you can kind of go poke more if you feel like it.\n\nBill Karpovich  1:09:06  \nBut fantastic. Yeah, this is great. This is helpful. Docs are great way to get smart on things, and obviously AI generated, which is great.\n\nSoren Frederiksen  1:09:17  \nWell, there's an agent in there too. If you go ask that, you could go ask about our product, which\n\nBill Karpovich  1:09:23  \nis just the search, or is there\n\nSoren Frederiksen  1:09:24  \nanother one? Yeah, just on the homepage. On the homepage in the docs, there's a big girl sitting there, and if you click on that, it takes you to an agent which is kind of like a rag of all of our documentation. And it's pretty good at answering most questions of whether or not, do they have a calculator for this, and how would you use to\n\nBill Karpovich  1:09:46  \nthis stuff? You guys using get book for this, by the way, or is this another something else? No, it's chat\n\nSoren Frederiksen  1:09:51  \nbased, actually, for the agent itself. Okay, cool.\n\nBill Karpovich  1:09:55  \nHey, Soren. Great stuff again. Thank you. Really enjoyed it. We will absolutely be in touch and we'll talk soon.\n\nSoren Frederiksen  1:10:01  \nOkay, good, okay, thanks, Bill,\n\nBill Karpovich  1:10:03  \nall right, thank you. Bye.\n\nTranscribed by https://otter.ai",
  "mediaFileName": null,
  "transcriptionFileName": null,
  "createdAt": "2025-12-02T00:26:58.843Z"
}